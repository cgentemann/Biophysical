{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "####################you will need to change some paths here!#####################\n",
    "#list of input files\n",
    "filename_northpac_eddies='F:/data/project_data/NASA_biophysical/aviso/eddy_trajectory_19930101_20170106_north_pacific_2020_10_06.nc'\n",
    "filename_cpr_eddy='F:/data/NASA_biophysical/collocated_data/CPR/eddy_cpr_data_north_pacific_2020_10_06.nc'\n",
    "filename_aviso_all='f:/data/project_data/NASA_biophysical/aviso/eddy_trajectory_19930101_20170106.nc'   #From AVISO  website\n",
    "filename_cpr_all='F:/data/project_data/NASA_biophysical//collocated_data/CPR/All CPR Sample catalogue with eddy info_2020_10_06.nc'\n",
    "#output files\n",
    "filename_cpr_expanded='f:/data/NASA_biophysical/collocated_data/CPR/All CPR Sample catalogue with eddy info_2020_10_06'\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function to read in data and put in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to get all the data at once, use same years for climatology for all data\n",
    "def get_data():\n",
    "    \n",
    "    #climatology years\n",
    "    cyr1,cyr2='1993-01-01','2018-12-31'\n",
    "    \n",
    "    # CCMP test\n",
    "    dir_pattern_zarr = 'F:/data/sat_data/ccmp/zarr/'\n",
    "    ds= xr.open_zarr(dir_pattern_zarr)\n",
    "    ds = ds.rename({'latitude':'lat','longitude':'lon'})\n",
    "    ds.coords['lon'] = (ds.coords['lon'] + 180) % 360 - 180\n",
    "    ds_ccmp = ds.sortby(ds.lon)\n",
    "    ds_ccmp = ds_ccmp.drop('nobs')\n",
    "    for var in ds_ccmp:\n",
    "        tem = ds_ccmp[var].attrs\n",
    "        tem['var_name']='ccmp_'+str(var)\n",
    "        ds_ccmp[var].attrs=tem\n",
    "    ds_ccmp_clim = ds_ccmp.sel(time=slice(cyr1,cyr2))\n",
    "    ds_ccmp_clim = ds_ccmp_clim.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)\n",
    "    \n",
    "    # AVISO test\n",
    "    dir_pattern_zarr = 'F:/data/sat_data/aviso/zarr/'\n",
    "    ds= xr.open_zarr(dir_pattern_zarr)\n",
    "    ds = ds.rename({'latitude':'lat','longitude':'lon'})\n",
    "    ds.coords['lon'] = (ds.coords['lon'] + 180) % 360 - 180\n",
    "    ds_aviso = ds.sortby(ds.lon).drop({'lat_bnds','lon_bnds','crs','err'})\n",
    "    for var in ds_aviso:\n",
    "        tem = ds_aviso[var].attrs\n",
    "        tem['var_name']='aviso_'+str(var)\n",
    "        ds_aviso[var].attrs=tem\n",
    "    ds_aviso_clim = ds_aviso.sel(time=slice(cyr1,cyr2))\n",
    "    ds_aviso_clim = ds_aviso_clim.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)    \n",
    "\n",
    "    #sst\n",
    "    dir_pattern_zarr = 'F:/data/sat_data/sst/cmc/zarr/'\n",
    "    ds_sst= xr.open_zarr(dir_pattern_zarr)\n",
    "    ds_sst = ds_sst.drop({'analysis_error','mask','sea_ice_fraction'})\n",
    "    tem = ds_sst.analysed_sst.attrs\n",
    "    tem['var_name']='cmc_sst'\n",
    "    ds_sst.analysed_sst.attrs=tem\n",
    "    ds_sst_clim = ds_sst.sel(time=slice(cyr1,cyr2))\n",
    "    ds_sst_clim = ds_sst_clim.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)\n",
    "    \n",
    "    #get bathymetry from ETOPO1\n",
    "    fname_topo = 'F:/data/topo/ETOPO1_Ice_g_gmt4.grd'\n",
    "    ds = xr.open_dataset(fname_topo)\n",
    "#    x = ds.x  #21601\n",
    "#    y = ds.y   #10801\n",
    "#    topo = ds.z  #(10801, 21601)\n",
    "    ds_topo = ds.rename_dims({'x':'lon','y':'lat'}).rename({'x':'lon','y':'lat'})\n",
    "    tem = ds_topo.z.attrs\n",
    "    tem['var_name']='etopo_depth'\n",
    "    ds_topo.z.attrs=tem\n",
    "#    ds_topo\n",
    "\n",
    "    #put data into a dictionary\n",
    "    data_dict={'aviso':ds_aviso,\n",
    "               'wnd':ds_ccmp,\n",
    "               'sst':ds_sst,\n",
    "              'topo':ds_topo}\n",
    "    clim_dict={'aviso_clim':ds_aviso_clim,\n",
    "               'wnd_clim':ds_ccmp_clim,\n",
    "               'sst_clim':ds_sst_clim}\n",
    "  \n",
    "    return data_dict,clim_dict\n",
    "\n",
    "def get_eddy(filename):\n",
    "    ds_eddy = xr.open_dataset(filename)\n",
    "    tt=np.empty(ds_eddy.z.size,dtype='datetime64[ns]') \n",
    "    for i in range(ds_eddy.z.size):\n",
    "        tstr=str(ds_eddy.cpr_sample_year[i].data)+'-'+str(ds_eddy.cpr_sample_month[i].data).zfill(2)+'-'+str(ds_eddy.cpr_sample_day[i].data).zfill(2)\n",
    "        tem=np.datetime64(tstr)\n",
    "        tt[i]=tem\n",
    "    ds_eddy['cpr_sample_time']=xr.DataArray(tt,dims=['z'])\n",
    "    return ds_eddy\n",
    "\n",
    "def get_all_eddy(filename):\n",
    "    ds = xr.open_dataset(filename)\n",
    "    ds['longitude'] = (ds['longitude'] + 180) % 360 - 180\n",
    "    ds_eddy = ds\n",
    "#    tt=np.empty(ds_eddy.obs.size,dtype='datetime64[ns]') \n",
    "#    for i in range(ds_eddy.obs.size):\n",
    "#        tstr=str(ds_eddy.time[i].dt.year.data)+'-'+str(ds_eddy.time[i].dt.month.data).zfill(2)+'-'+str(ds_eddy.time[i].dt.day.data).zfill(2)\n",
    "#        tem=np.datetime64(tstr)\n",
    "#        tt[i]=tem\n",
    "#    ds_eddy['cpr_sample_time']=xr.DataArray(tt,dims=['obs'])\n",
    "    return ds_eddy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,clim = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_eddy = get_eddy(filename_cpr_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:                           (z: 23306)\n",
       "Dimensions without coordinates: z\n",
       "Data variables:\n",
       "    cpr_eddy_data_index               (z) int32 ...\n",
       "    cpr_eddy_data_distance            (z) float32 ...\n",
       "    cpr_eddy_data_radius              (z) float32 ...\n",
       "    cpr_eddy_data_dist_from_land      (z) float32 ...\n",
       "    cpr_eddy_data_lon                 (z) float32 ...\n",
       "    cpr_eddy_data_lat                 (z) float32 ...\n",
       "    cpr_eddy_data_time                (z) datetime64[ns] ...\n",
       "    cpr_eddy_data_amplitude           (z) float32 ...\n",
       "    cpr_eddy_data_speed_average       (z) float32 ...\n",
       "    cpr_eddy_data_speed_radius        (z) float32 ...\n",
       "    cpr_eddy_data_cyclonic_type       (z) float64 ...\n",
       "    cpr_eddy_data_track               (z) float64 ...\n",
       "    cpr_eddy_data_track_total_days    (z) float64 ...\n",
       "    cpr_eddy_data_observation_number  (z) float64 ...\n",
       "    cpr_eddy_data_year                (z) float32 ...\n",
       "    cpr_eddy_data_idayjl              (z) float32 ...\n",
       "    num_cross                         (z) int32 ...\n",
       "    cpr_sample_id                     (z) object ...\n",
       "    cpr_sample_day                    (z) int64 ...\n",
       "    cpr_sample_month                  (z) int64 ...\n",
       "    cpr_sample_year                   (z) int64 ...\n",
       "    cpr_sample_lat                    (z) float64 ...\n",
       "    cpr_sample_lon                    (z) float64 ...\n",
       "    cpr_sample_proc                   (z) object ...\n",
       "    cpr_sample_time                   (z) datetime64[ns] 2000-03-20 ... 2016-11-11\n",
       "    cpr_sample_ETOPO_depth            (z) float64 ...\n",
       "    cpr_sample_lon2                   (z) float64 ...\n",
       "    cpr_sample_aviso_adt              (z) float64 ...\n",
       "    cpr_sample_aviso_sla              (z) float64 ...\n",
       "    cpr_sample_aviso_ugos             (z) float64 ...\n",
       "    cpr_sample_aviso_ugosa            (z) float64 ...\n",
       "    cpr_sample_aviso_vgos             (z) float64 ...\n",
       "    cpr_sample_aviso_vgosa            (z) float64 ...\n",
       "    cpr_sample_ccmp_uwnd              (z) float32 ...\n",
       "    cpr_sample_ccmp_vwnd              (z) float32 ...\n",
       "    cpr_sample_cmc_sst                (z) float32 ...</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:                           (z: 23306)\n",
       "Dimensions without coordinates: z\n",
       "Data variables:\n",
       "    cpr_eddy_data_index               (z) int32 ...\n",
       "    cpr_eddy_data_distance            (z) float32 ...\n",
       "    cpr_eddy_data_radius              (z) float32 ...\n",
       "    cpr_eddy_data_dist_from_land      (z) float32 ...\n",
       "    cpr_eddy_data_lon                 (z) float32 ...\n",
       "    cpr_eddy_data_lat                 (z) float32 ...\n",
       "    cpr_eddy_data_time                (z) datetime64[ns] ...\n",
       "    cpr_eddy_data_amplitude           (z) float32 ...\n",
       "    cpr_eddy_data_speed_average       (z) float32 ...\n",
       "    cpr_eddy_data_speed_radius        (z) float32 ...\n",
       "    cpr_eddy_data_cyclonic_type       (z) float64 ...\n",
       "    cpr_eddy_data_track               (z) float64 ...\n",
       "    cpr_eddy_data_track_total_days    (z) float64 ...\n",
       "    cpr_eddy_data_observation_number  (z) float64 ...\n",
       "    cpr_eddy_data_year                (z) float32 ...\n",
       "    cpr_eddy_data_idayjl              (z) float32 ...\n",
       "    num_cross                         (z) int32 ...\n",
       "    cpr_sample_id                     (z) object ...\n",
       "    cpr_sample_day                    (z) int64 ...\n",
       "    cpr_sample_month                  (z) int64 ...\n",
       "    cpr_sample_year                   (z) int64 ...\n",
       "    cpr_sample_lat                    (z) float64 ...\n",
       "    cpr_sample_lon                    (z) float64 ...\n",
       "    cpr_sample_proc                   (z) object ...\n",
       "    cpr_sample_time                   (z) datetime64[ns] 2000-03-20 ... 2016-11-11\n",
       "    cpr_sample_ETOPO_depth            (z) float64 ...\n",
       "    cpr_sample_lon2                   (z) float64 ...\n",
       "    cpr_sample_aviso_adt              (z) float64 ...\n",
       "    cpr_sample_aviso_sla              (z) float64 ...\n",
       "    cpr_sample_aviso_ugos             (z) float64 ...\n",
       "    cpr_sample_aviso_ugosa            (z) float64 ...\n",
       "    cpr_sample_aviso_vgos             (z) float64 ...\n",
       "    cpr_sample_aviso_vgosa            (z) float64 ...\n",
       "    cpr_sample_ccmp_uwnd              (z) float32 ...\n",
       "    cpr_sample_ccmp_vwnd              (z) float32 ...\n",
       "    cpr_sample_cmc_sst                (z) float32 ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_eddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename_aviso='f:/data/NASA_biophysical/aviso/eddy_trajectory_19930101_20170106.nc'   #From AVISO  website\n",
    "#ds_eddy = xr.open_dataset(filename_aviso)\n",
    "#ds_eddy\n",
    "#ds_all = get_all_eddy(filename_aviso_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocate all data with eddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name aviso\n",
      "var aviso_vgosa\n",
      "name wnd\n",
      "var ccmp_vwnd\n",
      "name sst\n",
      "var cmc_sst\n",
      "name aviso_clim\n",
      "var aviso_vgosa_clim\n",
      "name wnd_clim\n",
      "var ccmp_vwnd_clim\n",
      "name sst_clim\n",
      "var cmc_sst_clim\n"
     ]
    }
   ],
   "source": [
    "for name in data:\n",
    "    ds_data=data[name]\n",
    "    if name=='topo':\n",
    "        continue\n",
    "    print('name',name)\n",
    "    for var in ds_data:\n",
    "        var_tem=ds_data[var].attrs['var_name']\n",
    "        ds_eddy[var_tem]=ds_eddy.cpr_sample_ccmp_uwnd.copy(deep=True)*np.NaN\n",
    "        ds_eddy[var_tem].attrs=ds_data[var].attrs\n",
    "    print('var',var_tem)\n",
    "    for i in range(2): #ds_eddy.z.size):\n",
    "        lat1,lat2=ds_eddy.cpr_sample_lat[i].data-1,ds_eddy.cpr_sample_lat[i].data+1\n",
    "        lon1,lon2=ds_eddy.cpr_sample_lon[i].data-1,ds_eddy.cpr_sample_lon[i].data+1\n",
    "        #interp in time and select region around lat/lon to subset before loading data\n",
    "        tem = ds_data.interp(time=ds_eddy.cpr_sample_time[i].data).sel(lat=slice(lat1,lat2),lon=slice(lon1,lon2)).load()\n",
    "        tem = tem.interp(lat=ds_eddy.cpr_sample_lat[i].data,lon=ds_eddy.cpr_sample_lon[i].data)\n",
    "        for var in ds_data:\n",
    "            var_tem=ds_data[var].attrs['var_name']\n",
    "            ds_eddy[var_tem]=tem[var]\n",
    "for name in clim:\n",
    "    ds_data=clim[name]\n",
    "    print('name',name)\n",
    "    for var in ds_data:\n",
    "        var_tem=ds_data[var].attrs['var_name']+'_clim'\n",
    "        ds_eddy[var_tem]=ds_eddy.cpr_sample_ccmp_uwnd.copy(deep=True)*np.NaN\n",
    "        ds_eddy[var_tem].attrs=ds_data[var].attrs\n",
    "    print('var',var_tem)\n",
    "    for i in range(2): #ds_eddy.z.size):\n",
    "        lat1,lat2=ds_eddy.cpr_sample_lat[i].data-1,ds_eddy.cpr_sample_lat[i].data+1\n",
    "        lon1,lon2=ds_eddy.cpr_sample_lon[i].data-1,ds_eddy.cpr_sample_lon[i].data+1\n",
    "        #interp in time and select region around lat/lon to subset before loading data\n",
    "        tem = ds_data.sel(dayofyear=ds_eddy.cpr_sample_time[i].dt.dayofyear.data).sel(lat=slice(lat1,lat2),lon=slice(lon1,lon2)).load()\n",
    "        tem = tem.interp(lat=ds_eddy.cpr_sample_lat[i].data,lon=ds_eddy.cpr_sample_lon[i].data)\n",
    "        for var in ds_data:\n",
    "            var_tem=ds_data[var].attrs['var_name']+'_clim'\n",
    "            ds_eddy[var_tem]=tem[var]\n",
    "\n",
    "ds_topo=data['topo']\n",
    "ds_eddy['ETOPO_depth']=ds_topo.z.interp(lat=ds_eddy.cpr_sample_lat,lon=ds_eddy.cpr_sample_lon,method='nearest')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_out='F:/data/project_data/NASA_biophysical/collocated_data/CPR/All CPR Sample catalogue with eddy info_version2020_10_07.nc'\n",
    "ds_eddy.to_netcdf(filename_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOW, the point of this is to look up collocated eddy information and get the history of the data.  Steps are:\n",
    "1. Read in list of collocated eddies.\n",
    "2. Create list of unique eddy ID\n",
    "3. Read in full eddy database and select eddy id\n",
    "4. collocate environmental data for entire eddy history\n",
    "5. save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all = get_all_eddy(filename_aviso_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_eddy = get_eddy(filename_cpr_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all data where eddy radius < distance to eddy\n",
    "#find unique id & create a list\n",
    "subset = ds_eddy.where(ds_eddy.cpr_eddy_data_radius-ds_eddy.cpr_eddy_data_distance>0,drop=True)\n",
    "_, index = np.unique(subset['cpr_eddy_data_track_id'], return_index=True)\n",
    "eddy_list = subset['cpr_eddy_data_track_id'][index]\n",
    "print(eddy_list[0])\n",
    "#(subset.cpr_eddy_data_radius-subset.cpr_eddy_data_distance).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,clim = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eddy_list.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ieddy in eddy_list:\n",
    "for ieddy in range(eddy_list.size):\n",
    "    if ieddy<8:\n",
    "        continue\n",
    "    subset = ds_all.where(ds_all.track==eddy_list[ieddy],drop=True)\n",
    "    tt=np.empty(subset.obs.size,dtype='datetime64[ns]') \n",
    "    for i in range(subset.obs.size):\n",
    "        tstr=str(subset.time[i].dt.year.data)+'-'+str(subset.time[i].dt.month.data).zfill(2)+'-'+str(subset.time[i].dt.day.data).zfill(2)\n",
    "        tem=np.datetime64(tstr)\n",
    "        tt[i]=tem\n",
    "    subset['time']=xr.DataArray(tt,dims=['obs'])  \n",
    "    for name in data:\n",
    "        ds_data=data[name]\n",
    "        if name=='topo':\n",
    "            continue\n",
    "        print('name',name)\n",
    "        for var in ds_data:\n",
    "            var_tem=ds_data[var].attrs['var_name']\n",
    "            subset[var_tem]=subset.latitude.copy(deep=True)*np.NaN\n",
    "            subset[var_tem].attrs=ds_data[var].attrs\n",
    "        print('var',var_tem)\n",
    "        for i in range(subset.latitude.size):\n",
    "            lat1,lat2=subset.latitude[i].data-1,subset.latitude[i].data+1\n",
    "            lon1,lon2=subset.longitude[i].data-1,subset.longitude[i].data+1\n",
    "            #interp in time and select region around lat/lon to subset before loading data\n",
    "            #interp doesn't work on chunked dims so rechunk\n",
    "            ds_data2 = ds_data.chunk({'time':ds_data.time.size,'lat':ds_data[var].chunks[1],'lon':ds_data[var].chunks[2]})\n",
    "            #ds_data2.interp(time=subset.time[i].data)\n",
    "            tem = ds_data2.interp(time=subset.time[i].data).sel(lat=slice(lat1,lat2),lon=slice(lon1,lon2)).load()\n",
    "            tem = tem.interp(lat=subset.latitude[i].data,lon=subset.longitude[i].data)\n",
    "            for var in ds_data:\n",
    "                var_tem=ds_data[var].attrs['var_name']\n",
    "                subset[var_tem][i]=tem[var]\n",
    "    for name in clim:\n",
    "        ds_data=clim[name]\n",
    "        print('name',name)\n",
    "        for var in ds_data:\n",
    "            var_tem=ds_data[var].attrs['var_name']+'_clim'\n",
    "            subset[var_tem]=subset.latitude.copy(deep=True)*np.NaN\n",
    "            subset[var_tem].attrs=ds_data[var].attrs\n",
    "        print('var',var_tem)\n",
    "        for i in range(subset.latitude.size):\n",
    "            lat1,lat2=subset.latitude[i].data-1,subset.latitude[i].data+1\n",
    "            lon1,lon2=subset.longitude[i].data-1,subset.longitude[i].data+1\n",
    "            #interp in time and select region around lat/lon to subset before loading data\n",
    "            ds_data2 = ds_data.chunk({'dayofyear':ds_data.time.size,'lat':ds_data[var].chunks[1],'lon':ds_data[var].chunks[2]})\n",
    "            #ds_data2.interp(time=subset.time[i].data)\n",
    "            tem = ds_data2.sel(dayofyear=subset.time[i].dt.dayofyear.data).sel(lat=slice(lat1,lat2),lon=slice(lon1,lon2)).load()\n",
    "            tem = tem.interp(lat=subset.latitude[i].data,lon=subset.longitude[i].data)\n",
    "            for var in ds_data:\n",
    "                var_tem=ds_data[var].attrs['var_name']+'_clim'\n",
    "                subset[var_tem][i]=tem[var]\n",
    "    ds_topo=data['topo']\n",
    "    subset['ETOPO_depth']=ds_topo.z.interp(lat=subset.latitude,lon=subset.longitude,method='nearest')   \n",
    "    filename_out='F:/data/NASA_biophysical//collocated_data/eddy_collocated_data'+str(ieddy).zfill(8)+'.nc'\n",
    "    subset.to_netcdf(filename_out)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            ds_data2 = ds_data.chunk({'time':ds_data.time.size,'lat':ds_data[var].chunks[1],'lon':ds_data[var].chunks[2]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_data[var].chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_data[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(nrows=1, figsize=(6, 5.4))\n",
    "im = ax1.imshow(ds_topo.z[7000:9500,0:4500], interpolation='bilinear',vmin=-7000.0, vmax=1.0,aspect='auto',origin='lower')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
