{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "####################you will need to change some paths here!#####################\n",
    "#list of input files\n",
    "filename_cpr='f:/data/NASA_biophysical/CPR_data/All CPR Sample catalogue.xlsx'\n",
    "filename_northpac_eddies='F:/data/NASA_biophysical/aviso/eddy_trajectory_19930101_20170106_north_pacific.nc'\n",
    "filename_cpr_eddy='F:/data/NASA_biophysical/collocated_data/eddy_cpr_data_north_pacific.nc'\n",
    "filename_eddy='F:/data/NASA_biophysical/collocated_data/eddy_ranking_data_north_pacific.nc'\n",
    "#output files\n",
    "filename_cpr_expanded='f:/data/NASA_biophysical/collocated_data/All CPR Sample catalogue with eddy info2.xlsx'\n",
    "filename_cpr_expanded_netcdf='f:/data/NASA_biophysical/collocated_data/All CPR Sample catalogue with eddy info2.nc'\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function to read in data and put in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to get all the data at once, use same years for climatology for all data\n",
    "def get_data():\n",
    "    \n",
    "    #climatology years\n",
    "    cyr1,cyr2='1993-01-01','2018-12-31'\n",
    "    \n",
    "    # CCMP test\n",
    "    dir_pattern_zarr = 'F:/data/sat_data/ccmp/zarr/'\n",
    "    ds= xr.open_zarr(dir_pattern_zarr)\n",
    "    ds = ds.rename({'latitude':'lat','longitude':'lon'})\n",
    "    ds.coords['lon'] = (ds.coords['lon'] + 180) % 360 - 180\n",
    "    ds_ccmp = ds.sortby(ds.lon)\n",
    "    ds_ccmp = ds_ccmp.drop('nobs')\n",
    "    for var in ds_ccmp:\n",
    "        tem = ds_ccmp[var].attrs\n",
    "        tem['var_name']='ccmp_'+str(var)\n",
    "        ds_ccmp[var].attrs=tem\n",
    "    ds_ccmp_clim = ds_ccmp.sel(time=slice(cyr1,cyr2))\n",
    "    ds_ccmp_clim = ds_ccmp_clim.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)\n",
    "    \n",
    "    # AVISO test\n",
    "    dir_pattern_zarr = 'F:/data/sat_data/aviso/zarr/'\n",
    "    ds= xr.open_zarr(dir_pattern_zarr)\n",
    "    ds = ds.rename({'latitude':'lat','longitude':'lon'})\n",
    "    ds.coords['lon'] = (ds.coords['lon'] + 180) % 360 - 180\n",
    "    ds_aviso = ds.sortby(ds.lon).drop({'lat_bnds','lon_bnds','crs','err'})\n",
    "    for var in ds_aviso:\n",
    "        tem = ds_aviso[var].attrs\n",
    "        tem['var_name']='aviso_'+str(var)\n",
    "        ds_aviso[var].attrs=tem\n",
    "    ds_aviso_clim = ds_aviso.sel(time=slice(cyr1,cyr2))\n",
    "    ds_aviso_clim = ds_aviso_clim.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)    \n",
    "\n",
    "    #sst\n",
    "    dir_pattern_zarr = 'F:/data/sst/cmc/zarr/'\n",
    "    ds_sst= xr.open_zarr(dir_pattern_zarr)\n",
    "    ds_sst = ds_sst.drop({'analysis_error','mask','sea_ice_fraction'})\n",
    "    tem = ds_sst.analysed_sst.attrs\n",
    "    tem['var_name']='cmc_sst'\n",
    "    ds_sst.analysed_sst.attrs=tem\n",
    "    ds_sst_clim = ds_sst.sel(time=slice(cyr1,cyr2))\n",
    "    ds_sst_clim = ds_sst_clim.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)\n",
    "    \n",
    "    #get bathymetry from ETOPO1\n",
    "    fname_topo = 'F:/data/topo/ETOPO1_Ice_g_gmt4.grd'\n",
    "    ds = xr.open_dataset(fname_topo)\n",
    "#    x = ds.x  #21601\n",
    "#    y = ds.y   #10801\n",
    "#    topo = ds.z  #(10801, 21601)\n",
    "    ds_topo = ds.rename_dims({'x':'lon','y':'lat'}).rename({'x':'lon','y':'lat'})\n",
    "    tem = ds_topo.z.attrs\n",
    "    tem['var_name']='etopo_depth'\n",
    "    ds_topo.z.attrs=tem\n",
    "#    ds_topo\n",
    "\n",
    "    #put data into a dictionary\n",
    "    data_dict={'aviso':ds_aviso,\n",
    "               'wnd':ds_ccmp,\n",
    "               'sst':ds_sst,\n",
    "              'topo':ds_topo}\n",
    "    clim_dict={'aviso_clim':ds_aviso_clim,\n",
    "               'wnd_clim':ds_ccmp_clim,\n",
    "               'sst_clim':ds_sst_clim}\n",
    "  \n",
    "    return data_dict,clim_dict\n",
    "\n",
    "def get_eddy():\n",
    "    filename='F:/data/NASA_biophysical//collocated_data/All CPR Sample catalogue with eddy info4.nc'\n",
    "    ds_eddy = xr.open_dataset(filename)\n",
    "    tt=np.empty(ds_eddy.z.size,dtype='datetime64[ns]') \n",
    "    for i in range(ds_eddy.z.size):\n",
    "        tstr=str(ds_eddy.cpr_sample_year[i].data)+'-'+str(ds_eddy.cpr_sample_month[i].data).zfill(2)+'-'+str(ds_eddy.cpr_sample_day[i].data).zfill(2)\n",
    "        tem=np.datetime64(tstr)\n",
    "        tt[i]=tem\n",
    "    ds_eddy['cpr_sample_time']=xr.DataArray(tt,dims=['z'])\n",
    "    return ds_eddy\n",
    "\n",
    "def get_all_eddy():\n",
    "    filename_aviso='f:/data/NASA_biophysical/aviso/eddy_trajectory_19930101_20170106.nc'   #From AVISO  website\n",
    "    ds = xr.open_dataset(filename_aviso)\n",
    "    ds['longitude'] = (ds['longitude'] + 180) % 360 - 180\n",
    "    ds_eddy = ds\n",
    "#    tt=np.empty(ds_eddy.obs.size,dtype='datetime64[ns]') \n",
    "#    for i in range(ds_eddy.obs.size):\n",
    "#        tstr=str(ds_eddy.time[i].dt.year.data)+'-'+str(ds_eddy.time[i].dt.month.data).zfill(2)+'-'+str(ds_eddy.time[i].dt.day.data).zfill(2)\n",
    "#        tem=np.datetime64(tstr)\n",
    "#        tt[i]=tem\n",
    "#    ds_eddy['cpr_sample_time']=xr.DataArray(tt,dims=['obs'])\n",
    "    return ds_eddy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,clim = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_eddy = get_eddy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename_aviso='f:/data/NASA_biophysical/aviso/eddy_trajectory_19930101_20170106.nc'   #From AVISO  website\n",
    "#ds_eddy = xr.open_dataset(filename_aviso)\n",
    "#ds_eddy\n",
    "#ds_all = get_all_eddy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocate all data with eddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in data:\n",
    "    ds_data=data[name]\n",
    "    if name=='topo':\n",
    "        continue\n",
    "    print('name',name)\n",
    "    for var in ds_data:\n",
    "        var_tem=ds_data[var].attrs['var_name']\n",
    "        ds_eddy[var_tem]=ds_eddy.cpr_sample_ccmp_uwnd.copy(deep=True)*np.NaN\n",
    "        ds_eddy[var_tem].attrs=ds_data[var].attrs\n",
    "    print('var',var_tem)\n",
    "    for i in range(2): #ds_eddy.z.size):\n",
    "        lat1,lat2=ds_eddy.cpr_sample_lat[i].data-1,ds_eddy.cpr_sample_lat[i].data+1\n",
    "        lon1,lon2=ds_eddy.cpr_sample_lon[i].data-1,ds_eddy.cpr_sample_lon[i].data+1\n",
    "        #interp in time and select region around lat/lon to subset before loading data\n",
    "        tem = ds_data.interp(time=ds_eddy.cpr_sample_time[i].data).sel(lat=slice(lat1,lat2),lon=slice(lon1,lon2)).load()\n",
    "        tem = tem.interp(lat=ds_eddy.cpr_sample_lat[i].data,lon=ds_eddy.cpr_sample_lon[i].data)\n",
    "        for var in ds_data:\n",
    "            var_tem=ds_data[var].attrs['var_name']\n",
    "            ds_eddy[var_tem]=tem[var]\n",
    "for name in clim:\n",
    "    ds_data=clim[name]\n",
    "    print('name',name)\n",
    "    for var in ds_data:\n",
    "        var_tem=ds_data[var].attrs['var_name']+'_clim'\n",
    "        ds_eddy[var_tem]=ds_eddy.cpr_sample_ccmp_uwnd.copy(deep=True)*np.NaN\n",
    "        ds_eddy[var_tem].attrs=ds_data[var].attrs\n",
    "    print('var',var_tem)\n",
    "    for i in range(2): #ds_eddy.z.size):\n",
    "        lat1,lat2=ds_eddy.cpr_sample_lat[i].data-1,ds_eddy.cpr_sample_lat[i].data+1\n",
    "        lon1,lon2=ds_eddy.cpr_sample_lon[i].data-1,ds_eddy.cpr_sample_lon[i].data+1\n",
    "        #interp in time and select region around lat/lon to subset before loading data\n",
    "        tem = ds_data.sel(dayofyear=ds_eddy.cpr_sample_time[i].dt.dayofyear.data).sel(lat=slice(lat1,lat2),lon=slice(lon1,lon2)).load()\n",
    "        tem = tem.interp(lat=ds_eddy.cpr_sample_lat[i].data,lon=ds_eddy.cpr_sample_lon[i].data)\n",
    "        for var in ds_data:\n",
    "            var_tem=ds_data[var].attrs['var_name']+'_clim'\n",
    "            ds_eddy[var_tem]=tem[var]\n",
    "\n",
    "ds_topo=data['topo']\n",
    "ds_eddy['ETOPO_depth']=ds_topo.z.interp(lat=ds_eddy.cpr_sample_lat,lon=ds_eddy.cpr_sample_lon,method='nearest')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_out='F:/data/NASA_biophysical//collocated_data/All CPR Sample catalogue with eddy info_version2020_04_21.nc'\n",
    "ds_eddy.to_netcdf(filename_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOW, the point of this is to look up collocated eddy information and get the history of the data.  Steps are:\n",
    "1. Read in list of collocated eddies.\n",
    "2. Create list of unique eddy ID\n",
    "3. Read in full eddy database and select eddy id\n",
    "4. collocate environmental data for entire eddy history\n",
    "5. save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all = get_all_eddy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_eddy = get_eddy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all data where eddy radius < distance to eddy\n",
    "#find unique id & create a list\n",
    "subset = ds_eddy.where(ds_eddy.cpr_eddy_data_radius-ds_eddy.cpr_eddy_data_distance>0,drop=True)\n",
    "_, index = np.unique(subset['cpr_eddy_data_track_id'], return_index=True)\n",
    "eddy_list = subset['cpr_eddy_data_track_id'][index]\n",
    "print(eddy_list[0])\n",
    "#(subset.cpr_eddy_data_radius-subset.cpr_eddy_data_distance).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,clim = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ieddy in eddy_list:\n",
    "for ieddy in range(1):\n",
    "    subset = ds_all.where(ds_all.track==eddy_list[ieddy],drop=True)\n",
    "    tt=np.empty(subset.obs.size,dtype='datetime64[ns]') \n",
    "    for i in range(subset.obs.size):\n",
    "        tstr=str(subset.time[i].dt.year.data)+'-'+str(subset.time[i].dt.month.data).zfill(2)+'-'+str(subset.time[i].dt.day.data).zfill(2)\n",
    "        tem=np.datetime64(tstr)\n",
    "        tt[i]=tem\n",
    "    subset['time']=xr.DataArray(tt,dims=['obs'])  \n",
    "    for name in data:\n",
    "        ds_data=data[name]\n",
    "        if name=='topo':\n",
    "            continue\n",
    "        print('name',name)\n",
    "        for var in ds_data:\n",
    "            var_tem=ds_data[var].attrs['var_name']\n",
    "            subset[var_tem]=subset.latitude.copy(deep=True)*np.NaN\n",
    "            subset[var_tem].attrs=ds_data[var].attrs\n",
    "        print('var',var_tem)\n",
    "        for i in range(subset.latitude.size):\n",
    "            lat1,lat2=subset.latitude[i].data-1,subset.latitude[i].data+1\n",
    "            lon1,lon2=subset.longitude[i].data-1,subset.longitude[i].data+1\n",
    "            #interp in time and select region around lat/lon to subset before loading data\n",
    "            tem = ds_data.interp(time=subset.time[i].data).sel(lat=slice(lat1,lat2),lon=slice(lon1,lon2)).load()\n",
    "            tem = tem.interp(lat=subset.latitude[i].data,lon=subset.longitude[i].data)\n",
    "            for var in ds_data:\n",
    "                var_tem=ds_data[var].attrs['var_name']\n",
    "                subset[var_tem][i]=tem[var]\n",
    "    for name in clim:\n",
    "        ds_data=clim[name]\n",
    "        print('name',name)\n",
    "        for var in ds_data:\n",
    "            var_tem=ds_data[var].attrs['var_name']+'_clim'\n",
    "            subset[var_tem]=subset.latitude.copy(deep=True)*np.NaN\n",
    "            subset[var_tem].attrs=ds_data[var].attrs\n",
    "        print('var',var_tem)\n",
    "        for i in range(subset.latitude.size):\n",
    "            lat1,lat2=subset.latitude[i].data-1,subset.latitude[i].data+1\n",
    "            lon1,lon2=subset.longitude[i].data-1,subset.longitude[i].data+1\n",
    "            #interp in time and select region around lat/lon to subset before loading data\n",
    "            tem = ds_data.sel(dayofyear=subset.time[i].dt.dayofyear.data).sel(lat=slice(lat1,lat2),lon=slice(lon1,lon2)).load()\n",
    "            tem = tem.interp(lat=subset.latitude[i].data,lon=subset.longitude[i].data)\n",
    "            for var in ds_data:\n",
    "                var_tem=ds_data[var].attrs['var_name']+'_clim'\n",
    "                subset[var_tem][i]=tem[var]\n",
    "    ds_topo=data['topo']\n",
    "    subset['ETOPO_depth']=ds_topo.z.interp(lat=subset.latitude,lon=subset.longitude,method='nearest')   \n",
    "    filename_out='F:/data/NASA_biophysical//collocated_data/eddy_collocated_data'+str(ieddy).zfill(8)+'.nc'\n",
    "    subset.to_netcdf(filename_out)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(nrows=1, figsize=(6, 5.4))\n",
    "im = ax1.imshow(ds_topo.z[7000:9500,0:4500], interpolation='bilinear',vmin=-7000.0, vmax=1.0,aspect='auto',origin='lower')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
