{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import warnings\n",
    "# filter some warning messages\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "####################you will need to change some paths here!#####################\n",
    "#list of input files\n",
    "filename_bird='f:/data/NASA_biophysical/collocated_data/NPPSD_GOA_allseabird_wide.csv'\n",
    "#output files\n",
    "filename_bird_out='f:/data/NASA_biophysical/collocated_data/NPPSD_GOA_allseabird_wide_sat_data.csv'\n",
    "filename_bird_out_netcdf='f:/data/NASA_biophysical/collocated_data/NPPSD_GOA_allseabird_wide_sat_data.nc'\n",
    "#################################################################################\n",
    "#output files\n",
    "filename_bird_out_final='f:/data/NASA_biophysical/collocated_data/NPPSD_GOA_allseabird_wide_sat_clim_data.csv'\n",
    "filename_bird_out_netcdf_final='f:/data/NASA_biophysical/collocated_data/NPPSD_GOA_allseabird_wide_sat_clim_data.nc'\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in csv file in to panda dataframe\n",
    "ds_bird = pd.read_csv(filename_bird)\n",
    "#calculate time\n",
    "tem=np.ones(len(ds_bird),dtype='datetime64[ns]')\n",
    "for i in range(len(ds_bird)):\n",
    "    tstr = str(ds_bird.Year[i])+'-'+str(ds_bird.Month[i]).zfill(2)+'-'+str(ds_bird.Day[i]).zfill(2)\n",
    "    tem[i]=np.datetime64(tstr)\n",
    "ds_bird['time']=tem\n",
    "ds_bird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just check lat/lon & see looks okay\n",
    "plt.scatter(ds_bird.Lon,ds_bird.Lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function to read in data and put in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to get all the data at once, use same years for climatology for all data\n",
    "def get_data():\n",
    "    \n",
    "    #climatology years\n",
    "    cyr1,cyr2='1993-01-01','2018-12-31'\n",
    "    \n",
    "    # CCMP test\n",
    "    dir_pattern_zarr = 'F:/data/sat_data/ccmp/zarr/'\n",
    "    ds= xr.open_zarr(dir_pattern_zarr)\n",
    "    ds = ds.rename({'latitude':'lat','longitude':'lon'})\n",
    "    ds.coords['lon'] = (ds.coords['lon'] + 180) % 360 - 180\n",
    "    ds_ccmp = ds.sortby(ds.lon)\n",
    "    ds_ccmp = ds_ccmp.drop('nobs')\n",
    "    for var in ds_ccmp:\n",
    "        tem = ds_ccmp[var].attrs\n",
    "        tem['var_name']='ccmp_'+str(var)\n",
    "        ds_ccmp[var].attrs=tem\n",
    "    ds_ccmp_clim = ds_ccmp.sel(time=slice(cyr1,cyr2))\n",
    "    ds_ccmp_clim = ds_ccmp_clim.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)\n",
    "    \n",
    "    # AVISO test\n",
    "    dir_pattern_zarr = 'F:/data/sat_data/aviso/zarr/'\n",
    "    ds= xr.open_zarr(dir_pattern_zarr)\n",
    "    ds = ds.rename({'latitude':'lat','longitude':'lon'})\n",
    "    ds.coords['lon'] = (ds.coords['lon'] + 180) % 360 - 180\n",
    "    ds_aviso = ds.sortby(ds.lon).drop({'lat_bnds','lon_bnds','crs','err'})\n",
    "    for var in ds_aviso:\n",
    "        tem = ds_aviso[var].attrs\n",
    "        tem['var_name']='aviso_'+str(var)\n",
    "        ds_aviso[var].attrs=tem\n",
    "    ds_aviso_clim = ds_aviso.sel(time=slice(cyr1,cyr2))\n",
    "    ds_aviso_clim = ds_aviso_clim.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)    \n",
    "\n",
    "    #sst\n",
    "    dir_pattern_zarr = 'F:/data/sst/cmc/zarr/'\n",
    "    ds_sst= xr.open_zarr(dir_pattern_zarr)\n",
    "    ds_sst = ds_sst.drop({'analysis_error','mask','sea_ice_fraction'})\n",
    "    tem = ds_sst.analysed_sst.attrs\n",
    "    tem['var_name']='cmc_sst'\n",
    "    ds_sst.analysed_sst.attrs=tem\n",
    "    ds_sst_clim = ds_sst.sel(time=slice(cyr1,cyr2))\n",
    "    ds_sst_clim = ds_sst_clim.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)\n",
    "    \n",
    "    #get bathymetry from ETOPO1\n",
    "    fname_topo = 'F:/data/topo/ETOPO1_Ice_g_gmt4.grd'\n",
    "    ds = xr.open_dataset(fname_topo)\n",
    "    ds_topo = ds.rename_dims({'x':'lon','y':'lat'}).rename({'x':'lon','y':'lat'})\n",
    "    tem = ds_topo.z.attrs\n",
    "    tem['var_name']='etopo_depth'\n",
    "    ds_topo.z.attrs=tem\n",
    "\n",
    "    #put data into a dictionary\n",
    "    data_dict={'aviso':ds_aviso,\n",
    "               'wnd':ds_ccmp,\n",
    "               'sst':ds_sst,\n",
    "              'topo':ds_topo}\n",
    "    clim_dict={'aviso_clim':ds_aviso_clim,\n",
    "               'wnd_clim':ds_ccmp_clim,\n",
    "               'sst_clim':ds_sst_clim}\n",
    "  \n",
    "    return data_dict,clim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,clim = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocate all data with bird data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in data:\n",
    "    ds_data=data[name]\n",
    "    if name=='topo':\n",
    "        continue\n",
    "    print('name',name)\n",
    "    for var in ds_data:\n",
    "        var_tem=ds_data[var].attrs['var_name']\n",
    "        ds_bird[var_tem]=np.ones(len(ds_bird))*np.NaN\n",
    "        ds_bird[var_tem].attrs=ds_data[var].attrs\n",
    "    print('var',var_tem)\n",
    "    for i in range(len(ds_bird)):\n",
    "        if ds_bird.time[i]<ds_data.time.min():\n",
    "            continue\n",
    "        if ds_bird.time[i]>ds_data.time.max():\n",
    "            continue\n",
    "        t1,t2 = ds_bird.time[i]-np.timedelta64(24,'h'), ds_bird.time[i]+np.timedelta64(24,'h')\n",
    "        lat1,lat2=ds_bird.Lat[i]-.5,ds_bird.Lat[i]+.5\n",
    "        lon1,lon2=ds_bird.Lon[i]-.5,ds_bird.Lon[i]+.5\n",
    "        tem = ds_data.sel(time=slice(t1,t2),lat=slice(lat1,lat2),lon=slice(lon1,lon2)).load()\n",
    "        tem = tem.interp(time=ds_bird.time[i],lat=ds_bird.Lat[i],lon=ds_bird.Lon[i])\n",
    "        #tem = tem.load()\n",
    "        for var in ds_data:\n",
    "            var_tem=ds_data[var].attrs['var_name']\n",
    "            ds_bird[var_tem][i]=tem[var].data\n",
    "        if int(i/100)*100==i:\n",
    "            print(i,len(ds_bird))\n",
    "#at topo info\n",
    "#interp will create a new 2D array, to avoid that put the lat/lon into dataarrays\n",
    "ds_topo=data['topo']\n",
    "new_lat = xr.DataArray(ds_bird.Lat.values, dims='new_dim')\n",
    "new_lon = xr.DataArray(ds_bird.Lon.values, dims='new_dim')\n",
    "ds_bird['ETOPO_depth'] = ds_topo.z.interp(lat=new_lat, lon=new_lon,method='nearest')\n",
    "\n",
    "#output data\n",
    "ds_bird.to_csv(filename_bird_out)\n",
    "DS_bird = xr.Dataset.from_dataframe(ds_bird)\n",
    "DS_bird.to_netcdf(filename_bird_out_netcdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now add clim data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Master.Key</th>\n",
       "      <th>Modified.Platform.Type</th>\n",
       "      <th>Fly.Bird.Method</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Julian.Date</th>\n",
       "      <th>Sample.Area</th>\n",
       "      <th>...</th>\n",
       "      <th>aviso_adt</th>\n",
       "      <th>aviso_sla</th>\n",
       "      <th>aviso_ugos</th>\n",
       "      <th>aviso_ugosa</th>\n",
       "      <th>aviso_vgos</th>\n",
       "      <th>aviso_vgosa</th>\n",
       "      <th>ccmp_uwnd</th>\n",
       "      <th>ccmp_vwnd</th>\n",
       "      <th>cmc_sst</th>\n",
       "      <th>ETOPO_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>00008900289266113069</td>\n",
       "      <td>Large Boat</td>\n",
       "      <td>Snapshot</td>\n",
       "      <td>1989</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>266</td>\n",
       "      <td>0.92</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.627558</td>\n",
       "      <td>3.694584</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>00008900389266114069</td>\n",
       "      <td>Large Boat</td>\n",
       "      <td>Snapshot</td>\n",
       "      <td>1989</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>266</td>\n",
       "      <td>1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.657751</td>\n",
       "      <td>3.744639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>00008900489266115069</td>\n",
       "      <td>Large Boat</td>\n",
       "      <td>Snapshot</td>\n",
       "      <td>1989</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>266</td>\n",
       "      <td>0.92</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.706715</td>\n",
       "      <td>3.808849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>00008900589266120069</td>\n",
       "      <td>Large Boat</td>\n",
       "      <td>Snapshot</td>\n",
       "      <td>1989</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>266</td>\n",
       "      <td>1.01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.800105</td>\n",
       "      <td>3.906118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>00008900689266121069</td>\n",
       "      <td>Large Boat</td>\n",
       "      <td>Snapshot</td>\n",
       "      <td>1989</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>266</td>\n",
       "      <td>0.82</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.891196</td>\n",
       "      <td>4.004569</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92733</th>\n",
       "      <td>92733</td>\n",
       "      <td>92734</td>\n",
       "      <td>WOL 2018-07-17 21:57:58</td>\n",
       "      <td>Large Boat</td>\n",
       "      <td>Snapshot</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>198</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454218</td>\n",
       "      <td>0.010080</td>\n",
       "      <td>0.083981</td>\n",
       "      <td>0.099951</td>\n",
       "      <td>-0.065987</td>\n",
       "      <td>-0.034954</td>\n",
       "      <td>5.850998</td>\n",
       "      <td>0.916850</td>\n",
       "      <td>284.683242</td>\n",
       "      <td>-182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92734</th>\n",
       "      <td>92734</td>\n",
       "      <td>92735</td>\n",
       "      <td>WOL 2018-07-17 22:08:40</td>\n",
       "      <td>Large Boat</td>\n",
       "      <td>Snapshot</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>198</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454670</td>\n",
       "      <td>0.010279</td>\n",
       "      <td>0.088105</td>\n",
       "      <td>0.105073</td>\n",
       "      <td>-0.069213</td>\n",
       "      <td>-0.038192</td>\n",
       "      <td>5.894030</td>\n",
       "      <td>0.930526</td>\n",
       "      <td>284.706237</td>\n",
       "      <td>-174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92735</th>\n",
       "      <td>92735</td>\n",
       "      <td>92736</td>\n",
       "      <td>WOL 2018-07-17 22:19:02</td>\n",
       "      <td>Large Boat</td>\n",
       "      <td>Snapshot</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>198</td>\n",
       "      <td>0.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454823</td>\n",
       "      <td>0.010547</td>\n",
       "      <td>0.091983</td>\n",
       "      <td>0.109670</td>\n",
       "      <td>-0.069996</td>\n",
       "      <td>-0.038922</td>\n",
       "      <td>5.942175</td>\n",
       "      <td>0.944419</td>\n",
       "      <td>284.728114</td>\n",
       "      <td>-169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92736</th>\n",
       "      <td>92736</td>\n",
       "      <td>92737</td>\n",
       "      <td>WOL 2018-07-17 22:28:44</td>\n",
       "      <td>Large Boat</td>\n",
       "      <td>Snapshot</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>198</td>\n",
       "      <td>0.59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454695</td>\n",
       "      <td>0.010891</td>\n",
       "      <td>0.095475</td>\n",
       "      <td>0.113602</td>\n",
       "      <td>-0.068352</td>\n",
       "      <td>-0.037134</td>\n",
       "      <td>5.995787</td>\n",
       "      <td>0.958700</td>\n",
       "      <td>284.751116</td>\n",
       "      <td>-181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92737</th>\n",
       "      <td>92737</td>\n",
       "      <td>92738</td>\n",
       "      <td>WOL 2018-07-17 22:38:46</td>\n",
       "      <td>Large Boat</td>\n",
       "      <td>Snapshot</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>198</td>\n",
       "      <td>0.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455609</td>\n",
       "      <td>0.012273</td>\n",
       "      <td>0.096315</td>\n",
       "      <td>0.114128</td>\n",
       "      <td>-0.066765</td>\n",
       "      <td>-0.035501</td>\n",
       "      <td>6.020114</td>\n",
       "      <td>0.956194</td>\n",
       "      <td>284.761306</td>\n",
       "      <td>-185.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92738 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1               Master.Key  \\\n",
       "0               0             1     00008900289266113069   \n",
       "1               1             2     00008900389266114069   \n",
       "2               2             3     00008900489266115069   \n",
       "3               3             4     00008900589266120069   \n",
       "4               4             5     00008900689266121069   \n",
       "...           ...           ...                      ...   \n",
       "92733       92733         92734  WOL 2018-07-17 21:57:58   \n",
       "92734       92734         92735  WOL 2018-07-17 22:08:40   \n",
       "92735       92735         92736  WOL 2018-07-17 22:19:02   \n",
       "92736       92736         92737  WOL 2018-07-17 22:28:44   \n",
       "92737       92737         92738  WOL 2018-07-17 22:38:46   \n",
       "\n",
       "      Modified.Platform.Type Fly.Bird.Method  Year  Month  Day  Julian.Date  \\\n",
       "0                 Large Boat        Snapshot  1989      9   23          266   \n",
       "1                 Large Boat        Snapshot  1989      9   23          266   \n",
       "2                 Large Boat        Snapshot  1989      9   23          266   \n",
       "3                 Large Boat        Snapshot  1989      9   23          266   \n",
       "4                 Large Boat        Snapshot  1989      9   23          266   \n",
       "...                      ...             ...   ...    ...  ...          ...   \n",
       "92733             Large Boat        Snapshot  2018      7   17          198   \n",
       "92734             Large Boat        Snapshot  2018      7   17          198   \n",
       "92735             Large Boat        Snapshot  2018      7   17          198   \n",
       "92736             Large Boat        Snapshot  2018      7   17          198   \n",
       "92737             Large Boat        Snapshot  2018      7   17          198   \n",
       "\n",
       "       Sample.Area  ... aviso_adt  aviso_sla  aviso_ugos  aviso_ugosa  \\\n",
       "0             0.92  ...       NaN        NaN         NaN          NaN   \n",
       "1             1.10  ...       NaN        NaN         NaN          NaN   \n",
       "2             0.92  ...       NaN        NaN         NaN          NaN   \n",
       "3             1.01  ...       NaN        NaN         NaN          NaN   \n",
       "4             0.82  ...       NaN        NaN         NaN          NaN   \n",
       "...            ...  ...       ...        ...         ...          ...   \n",
       "92733         0.58  ...  0.454218   0.010080    0.083981     0.099951   \n",
       "92734         0.58  ...  0.454670   0.010279    0.088105     0.105073   \n",
       "92735         0.57  ...  0.454823   0.010547    0.091983     0.109670   \n",
       "92736         0.59  ...  0.454695   0.010891    0.095475     0.113602   \n",
       "92737         0.57  ...  0.455609   0.012273    0.096315     0.114128   \n",
       "\n",
       "       aviso_vgos  aviso_vgosa  ccmp_uwnd  ccmp_vwnd     cmc_sst  ETOPO_depth  \n",
       "0             NaN          NaN  -4.627558   3.694584         NaN        -13.0  \n",
       "1             NaN          NaN  -4.657751   3.744639         NaN        -20.0  \n",
       "2             NaN          NaN  -4.706715   3.808849         NaN        -21.0  \n",
       "3             NaN          NaN  -4.800105   3.906118         NaN        -23.0  \n",
       "4             NaN          NaN  -4.891196   4.004569         NaN        -20.0  \n",
       "...           ...          ...        ...        ...         ...          ...  \n",
       "92733   -0.065987    -0.034954   5.850998   0.916850  284.683242       -182.0  \n",
       "92734   -0.069213    -0.038192   5.894030   0.930526  284.706237       -174.0  \n",
       "92735   -0.069996    -0.038922   5.942175   0.944419  284.728114       -169.0  \n",
       "92736   -0.068352    -0.037134   5.995787   0.958700  284.751116       -181.0  \n",
       "92737   -0.066765    -0.035501   6.020114   0.956194  284.761306       -185.0  \n",
       "\n",
       "[92738 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in csv file in to panda dataframe\n",
    "ds_bird = pd.read_csv(filename_bird_out)\n",
    "#calculate time\n",
    "tem=np.ones(len(ds_bird),dtype='datetime64[ns]')\n",
    "for i in range(len(ds_bird)):\n",
    "    tstr = str(ds_bird.Year[i])+'-'+str(ds_bird.Month[i]).zfill(2)+'-'+str(ds_bird.Day[i]).zfill(2)\n",
    "    tem[i]=np.datetime64(tstr)\n",
    "ds_bird['time']=tem\n",
    "ds_bird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name aviso_clim\n",
      "var aviso_vgosa_clim\n"
     ]
    }
   ],
   "source": [
    "for name in clim:\n",
    "    ds_data=clim[name]\n",
    "    print('name',name)\n",
    "    for var in ds_data:\n",
    "        var_tem=ds_data[var].attrs['var_name']+'_clim'\n",
    "        ds_bird[var_tem]=np.ones(len(ds_bird))*np.NaN\n",
    "        ds_bird[var_tem].attrs=ds_data[var].attrs\n",
    "    print('var',var_tem)\n",
    "    for i in range(len(ds_bird)):\n",
    "        t1,t2 = ds_bird.time[i]-np.timedelta64(24,'h'), ds_bird.time[i]+np.timedelta64(24,'h')\n",
    "        lat1,lat2=ds_bird.Lat[i]-.5,ds_bird.Lat[i]+.5\n",
    "        lon1,lon2=ds_bird.Lon[i]-.5,ds_bird.Lon[i]+.5\n",
    "        tem = ds_data.sel(dayofyear=ds_bird.time[i].dayofyear,lat=slice(lat1,lat2),lon=slice(lon1,lon2)).load()\n",
    "        tem = tem.interp(lat=ds_bird.Lat[i],lon=ds_bird.Lon[i])\n",
    "        for var in ds_data:\n",
    "            var_tem=ds_data[var].attrs['var_name']+'_clim'\n",
    "            ds_bird[var_tem][i]=tem[var].data\n",
    "            \n",
    "#output data\n",
    "ds_bird.to_csv(filename_bird_out_final)\n",
    "DS_bird = xr.Dataset.from_dataframe(ds_bird)\n",
    "DS_bird.to_netcdf(filename_bird_out_netcdf_final)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:    (dayofyear: 366, lat: 720, lon: 1440, nv: 2)\n",
       "Coordinates:\n",
       "  * lon        (lon) float32 -179.875 -179.625 -179.375 ... 179.625 179.875\n",
       "  * lat        (lat) float32 -89.875 -89.625 -89.375 ... 89.375 89.625 89.875\n",
       "  * nv         (nv) int32 0 1\n",
       "  * dayofyear  (dayofyear) int64 1 2 3 4 5 6 7 8 ... 360 361 362 363 364 365 366\n",
       "Data variables:\n",
       "    adt        (dayofyear, lat, lon) float64 dask.array&lt;chunksize=(1, 180, 180), meta=np.ndarray&gt;\n",
       "    sla        (dayofyear, lat, lon) float64 dask.array&lt;chunksize=(1, 180, 180), meta=np.ndarray&gt;\n",
       "    ugos       (dayofyear, lat, lon) float64 dask.array&lt;chunksize=(1, 180, 180), meta=np.ndarray&gt;\n",
       "    ugosa      (dayofyear, lat, lon) float64 dask.array&lt;chunksize=(1, 180, 180), meta=np.ndarray&gt;\n",
       "    vgos       (dayofyear, lat, lon) float64 dask.array&lt;chunksize=(1, 180, 180), meta=np.ndarray&gt;\n",
       "    vgosa      (dayofyear, lat, lon) float64 dask.array&lt;chunksize=(1, 180, 180), meta=np.ndarray&gt;\n",
       "Attributes:\n",
       "    Conventions:                     CF-1.6\n",
       "    Metadata_Conventions:            Unidata Dataset Discovery v1.0\n",
       "    cdm_data_type:                   Grid\n",
       "    comment:                         Sea Surface Height measured by Altimetry...\n",
       "    contact:                         servicedesk.cmems@mercator-ocean.eu\n",
       "    creator_email:                   servicedesk.cmems@mercator-ocean.eu\n",
       "    creator_name:                    CMEMS - Sea Level Thematic Assembly Center\n",
       "    creator_url:                     http://marine.copernicus.eu\n",
       "    date_created:                    2019-09-11T21:09:34Z\n",
       "    date_issued:                     2019-09-11T21:09:34Z\n",
       "    date_modified:                   2019-09-11T21:09:34Z\n",
       "    geospatial_lat_max:              89.875\n",
       "    geospatial_lat_min:              -89.875\n",
       "    geospatial_lat_resolution:       0.25\n",
       "    geospatial_lat_units:            degrees_north\n",
       "    geospatial_lon_max:              359.875\n",
       "    geospatial_lon_min:              0.125\n",
       "    geospatial_lon_resolution:       0.25\n",
       "    geospatial_lon_units:            degrees_east\n",
       "    geospatial_vertical_max:         0.0\n",
       "    geospatial_vertical_min:         0.0\n",
       "    geospatial_vertical_positive:    down\n",
       "    geospatial_vertical_resolution:  point\n",
       "    geospatial_vertical_units:       m\n",
       "    history:                         2019-09-11 21:09:35Z: Creation\n",
       "    institution:                     CLS, CNES\n",
       "    keywords:                        Oceans &gt; Ocean Topography &gt; Sea Surface ...\n",
       "    keywords_vocabulary:             NetCDF COARDS Climate and Forecast Stand...\n",
       "    license:                         http://marine.copernicus.eu/web/27-servi...\n",
       "    platform:                        Altika Drifting Phase, Cryosat-2, Haiyan...\n",
       "    processing_level:                L4\n",
       "    product_version:                 2019\n",
       "    project:                         COPERNICUS MARINE ENVIRONMENT MONITORING...\n",
       "    references:                      http://marine.copernicus.eu\n",
       "    software_version:                6.3_DUACS_DT2018_baseline\n",
       "    source:                          Altimetry measurements\n",
       "    ssalto_duacs_comment:            The reference mission used for the altim...\n",
       "    standard_name_vocabulary:        NetCDF Climate and Forecast (CF) Metadat...\n",
       "    summary:                         SSALTO/DUACS Delayed-Time Level-4 sea su...\n",
       "    time_coverage_duration:          P1D\n",
       "    time_coverage_end:               2019-01-13T00:00:00Z\n",
       "    time_coverage_resolution:        P1D\n",
       "    time_coverage_start:             2019-01-13T00:00:00Z\n",
       "    title:                           DT merged all satellites Global Ocean Gr...</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (dayofyear: 366, lat: 720, lon: 1440, nv: 2)\n",
       "Coordinates:\n",
       "  * lon        (lon) float32 -179.875 -179.625 -179.375 ... 179.625 179.875\n",
       "  * lat        (lat) float32 -89.875 -89.625 -89.375 ... 89.375 89.625 89.875\n",
       "  * nv         (nv) int32 0 1\n",
       "  * dayofyear  (dayofyear) int64 1 2 3 4 5 6 7 8 ... 360 361 362 363 364 365 366\n",
       "Data variables:\n",
       "    adt        (dayofyear, lat, lon) float64 dask.array<chunksize=(1, 180, 180), meta=np.ndarray>\n",
       "    sla        (dayofyear, lat, lon) float64 dask.array<chunksize=(1, 180, 180), meta=np.ndarray>\n",
       "    ugos       (dayofyear, lat, lon) float64 dask.array<chunksize=(1, 180, 180), meta=np.ndarray>\n",
       "    ugosa      (dayofyear, lat, lon) float64 dask.array<chunksize=(1, 180, 180), meta=np.ndarray>\n",
       "    vgos       (dayofyear, lat, lon) float64 dask.array<chunksize=(1, 180, 180), meta=np.ndarray>\n",
       "    vgosa      (dayofyear, lat, lon) float64 dask.array<chunksize=(1, 180, 180), meta=np.ndarray>\n",
       "Attributes:\n",
       "    Conventions:                     CF-1.6\n",
       "    Metadata_Conventions:            Unidata Dataset Discovery v1.0\n",
       "    cdm_data_type:                   Grid\n",
       "    comment:                         Sea Surface Height measured by Altimetry...\n",
       "    contact:                         servicedesk.cmems@mercator-ocean.eu\n",
       "    creator_email:                   servicedesk.cmems@mercator-ocean.eu\n",
       "    creator_name:                    CMEMS - Sea Level Thematic Assembly Center\n",
       "    creator_url:                     http://marine.copernicus.eu\n",
       "    date_created:                    2019-09-11T21:09:34Z\n",
       "    date_issued:                     2019-09-11T21:09:34Z\n",
       "    date_modified:                   2019-09-11T21:09:34Z\n",
       "    geospatial_lat_max:              89.875\n",
       "    geospatial_lat_min:              -89.875\n",
       "    geospatial_lat_resolution:       0.25\n",
       "    geospatial_lat_units:            degrees_north\n",
       "    geospatial_lon_max:              359.875\n",
       "    geospatial_lon_min:              0.125\n",
       "    geospatial_lon_resolution:       0.25\n",
       "    geospatial_lon_units:            degrees_east\n",
       "    geospatial_vertical_max:         0.0\n",
       "    geospatial_vertical_min:         0.0\n",
       "    geospatial_vertical_positive:    down\n",
       "    geospatial_vertical_resolution:  point\n",
       "    geospatial_vertical_units:       m\n",
       "    history:                         2019-09-11 21:09:35Z: Creation\n",
       "    institution:                     CLS, CNES\n",
       "    keywords:                        Oceans > Ocean Topography > Sea Surface ...\n",
       "    keywords_vocabulary:             NetCDF COARDS Climate and Forecast Stand...\n",
       "    license:                         http://marine.copernicus.eu/web/27-servi...\n",
       "    platform:                        Altika Drifting Phase, Cryosat-2, Haiyan...\n",
       "    processing_level:                L4\n",
       "    product_version:                 2019\n",
       "    project:                         COPERNICUS MARINE ENVIRONMENT MONITORING...\n",
       "    references:                      http://marine.copernicus.eu\n",
       "    software_version:                6.3_DUACS_DT2018_baseline\n",
       "    source:                          Altimetry measurements\n",
       "    ssalto_duacs_comment:            The reference mission used for the altim...\n",
       "    standard_name_vocabulary:        NetCDF Climate and Forecast (CF) Metadat...\n",
       "    summary:                         SSALTO/DUACS Delayed-Time Level-4 sea su...\n",
       "    time_coverage_duration:          P1D\n",
       "    time_coverage_end:               2019-01-13T00:00:00Z\n",
       "    time_coverage_resolution:        P1D\n",
       "    time_coverage_start:             2019-01-13T00:00:00Z\n",
       "    title:                           DT merged all satellites Global Ocean Gr..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "name='aviso'\n",
    "i=900\n",
    "#ds_data=data[name]\n",
    "#tem = ds_data.chunk({'time':len(ds_data.time),'lat':180,'lon':180})\n",
    "#tem = tem.interp(time=ds_bird.time[i])\n",
    "#print(len(tem.time.dims))\n",
    "#print(tem)\n",
    "#tem = tem.load()\n",
    "#if len(tem.time.dims)<1:\n",
    "#    continue\n",
    "t1 = ds_bird.time[i]-np.timedelta64(24,'h')\n",
    "t2 = ds_bird.time[i]+np.timedelta64(24,'h')\n",
    "lat1=ds_bird.Lat[i]-.5\n",
    "lat2=ds_bird.Lat[i]+.5\n",
    "lon1=ds_bird.Lon[i]-.5\n",
    "lon2=ds_bird.Lon[i]+.5\n",
    "tem = ds_data.sel(time=slice(t1,t2),lat=slice(lat1,lat2),lon=slice(lon1,lon2))\n",
    "tem = tem.interp(time=ds_bird.time[i],lat=ds_bird.Lat[i],lon=ds_bird.Lon[i])\n",
    "tem = tem.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for var in ds_data:\n",
    "        var_tem=ds_data[var].attrs['var_name']\n",
    "        ds_bird[var_tem]=np.ones(len(ds_bird))*np.NaN\n",
    "        ds_bird[var_tem].attrs=ds_data[var].attrs\n",
    "    for var in ds_data:\n",
    "        var_tem=ds_data[var].attrs['var_name']\n",
    "        ds_bird[var_tem][i]=tem[var].data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bird[var_tem][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in clim:\n",
    "    ds_data=clim[name]\n",
    "    print('name',name)\n",
    "    for var in ds_data:\n",
    "        var_tem=ds_data[var].attrs['var_name']+'_clim'\n",
    "        ds_bird[var_tem]=np.ones(len(ds_bird))*np.NaN\n",
    "        ds_bird[var_tem].attrs=ds_data[var].attrs\n",
    "    print('var',var_tem)\n",
    "    for i in range(100): #len(ds_bird)):\n",
    "        lat1=ds_bird.Lat[i]-.5\n",
    "        lat2=ds_bird.Lat[i]+.5\n",
    "        lon1=ds_bird.Lon[i]-.5\n",
    "        lon2=ds_bird.Lon[i]+.5\n",
    "        tem = ds_data.sel(dayofyear=ds_bird.time[i].dayofyear,lat=slice(lat1,lat2),lon=slice(lon1,lon2)).load()\n",
    " #       tem = tem.chunk({'lat':len(ds_data.lat),'lon':len(ds_data.lon)})\n",
    "        tem = tem.interp(lat=ds_bird.Lat[i],lon=ds_bird.Lon[i])\n",
    "        for var in ds_data:\n",
    "            var_tem=ds_data[var].attrs['var_name']+'_clim'\n",
    "            ds_bird[var_tem][i]=tem[var].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bird.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem2 = tem\n",
    "print(type(tem2))\n",
    "tem2 = tem2.append(tem, ignore_index=True)\n",
    "tem2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        lat1,lat2=ds_bird.Lat[i]-.5,ds_bird.Lat[i]+.5\n",
    "        lon1,lon2=ds_bird.Lat[i]-.5,ds_bird.Lat[i]+.5\n",
    "        tem = ds_data.sel(dayofyear=ds_bird.time[i].dayofyear,lat=slice(lat1,lat2),lon=slice(lon1,lon2)).load()\n",
    " #       tem = tem.chunk({'lat':len(ds_data.lat),'lon':len(ds_data.lon)})\n",
    "        tem2 = tem.interp(lat=ds_bird.Lat[i],lon=ds_bird.Lon[i])\n",
    "#        for var in ds_data:\n",
    "#            var_tem=ds_data[var].attrs['var_name']+'_clim'\n",
    "#            ds_bird[var_tem][i]=tem2[var].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    for var in ds_data:\n",
    "#        var_tem=ds_data[var].attrs['var_name']+'_clim'\n",
    "#        ds_bird[var_tem]=np.ones(len(ds_bird))*np.NaN\n",
    "#        ds_bird[var_tem].attrs=ds_data[var].attrs\n",
    "\n",
    "ds_bird['test']=np.ones(len(ds_bird))*np.nan\n",
    "ds_bird['test'][i]=tem2[var].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bird[var_tem][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for idy in range(365):\n",
    "        tem = ds_data.sel(dayofyear=idy).load()\n",
    "        for i in range(len(ds_bird)):\n",
    "            if idy==ds_bird.time[i].dayofyear\n",
    "                tem = tem.interp(lat=ds_bird.Lat[i],lon=ds_bird.Lon[i]).load()\n",
    "                for var in ds_data:\n",
    "                    var_tem=ds_data[var].attrs['var_name']+'_clim'\n",
    "                    ds_bird[var_tem]=tem[var].data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test topo\n",
    "plt.scatter(ds_bird.Lon,ds_bird.Lat,c=ds_bird['ETOPO_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ds_bird.Lon,ds_bird.Lat,c=ds_bird.aviso_sla_clim,vmin=-0.01,vmax=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bird.aviso_sla_clim.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
