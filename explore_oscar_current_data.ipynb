{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from palettable import colorbrewer\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as colors\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.examples.arrows import sample_data\n",
    "#for movie\n",
    "import holoviews as hv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#climatology\n",
    "dir_data = 'F:/data/sat_data/oscar/L4/oscar_third_deg/'\n",
    "filename = dir_data + 'climatology_1993_2018_monthly_data_oscar.nc'\n",
    "ds=xr.open_dataset(filename)\n",
    "ds.close()\n",
    "ds = ds.sel(lon=slice(110,250),lat=slice(65,5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put 5 day data into one big array or next section is for monthly (smaller)\n",
    "dir_data = 'F:/data/sat_data/oscar/L4/oscar_third_deg/'\n",
    "for lyr in range(1993,2018): #2019): #2017):\n",
    "    filename = dir_data + 'oscar_vel' + str(lyr).zfill(4) + '.nc'\n",
    "    ds=xr.open_dataset(filename,drop_variables=['um','vm'])\n",
    "    ds = ds.rename({'longitude':'lon','latitude':'lat'})\n",
    "    ds = ds.drop('year')\n",
    "    ds['spd']=np.sqrt(ds.u*ds.u+ds.v*ds.v)\n",
    "    ds_subset = ds.sel(longitude=slice(110,250),latitude=slice(65,0))\n",
    "    ds.close()\n",
    "    if lyr==1993:\n",
    "        ds_all = ds_subset\n",
    "    else:\n",
    "        ds_all=xr.concat([ds_all,ds_subset],'time')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put monthly data into one big array\n",
    "dir_data = 'F:/data/sat_data/oscar/L4/oscar_third_deg/'\n",
    "for lyr in range(1993,2018): #2019): #2017):\n",
    "    filename = dir_data + str(lyr) + 'monthly_data_oscar.nc'\n",
    "    ds=xr.open_dataset(filename)\n",
    "    ds_subset = ds.sel(lon=slice(120,250),lat=slice(65,15))\n",
    "    ds.close()\n",
    "    if lyr==1993:\n",
    "        ds_all = ds_subset\n",
    "    else:\n",
    "        ds_all=xr.concat([ds_all,ds_subset],'time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (depth: 1, lat: 151, lon: 391, time: 300, year: 1800)\n",
       "Coordinates:\n",
       "  * year     (year) float64 1.993e+03 1.993e+03 ... 2.018e+03 2.018e+03\n",
       "  * depth    (depth) float32 15.0\n",
       "  * lat      (lat) float64 65.0 64.67 64.33 64.0 63.67 ... 16.0 15.67 15.33 15.0\n",
       "  * lon      (lon) float64 120.0 120.3 120.7 121.0 ... 249.0 249.3 249.7 250.0\n",
       "  * time     (time) datetime64[ns] 1993-01-31 1993-02-28 ... 2017-12-31\n",
       "Data variables:\n",
       "    u        (time, depth, lat, lon) float64 nan nan nan ... -0.01118 -0.04393\n",
       "    v        (time, depth, lat, lon) float64 nan nan nan ... -0.02956 0.0342\n",
       "    spd      (time, depth, lat, lon) float64 nan nan nan ... 0.05109 0.08189\n",
       "    dir      (time, depth, lat, lon) float64 nan nan nan ... -60.87 -52.98 69.87"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'type' and 'datetime.datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-262-698484067eb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mds_subset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'type' and 'datetime.datetime'"
     ]
    }
   ],
   "source": [
    "ds_subset = ds_all.sel(time>dt.datetime(2000,1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,1,figsize=(4,4))\n",
    "ds_all.spd[0,0,:,:].plot(vmin=0,vmax=.3)\n",
    "fig.savefig('F:/data/NASA_biophysical/telecon_figs/' + 'map.png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,1,figsize=(4,4))\n",
    "ds_subset = ds_all.sel(lon=slice(180,225),lat=slice(65,40))\n",
    "ds_subset.spd[120,0,:,:].plot(vmin=0,vmax=.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lat = np.empty(250)\n",
    "max_lat = np.empty(250)\n",
    "#max_lat[185:]=[52.0,52.1,52.1,52.1,54]\n",
    "for cen_lon in range(185,195):\n",
    "    fig, axarr = plt.subplots(1,1,figsize=(4,4))\n",
    "    ds_subset = ds_all.sel(lon=slice(cen_lon,cen_lon),lat=slice(60,50))\n",
    "    ds_subset.spd[84:,0,:,:].transpose().plot(vmin=0,vmax=.3)\n",
    "    fig.savefig('F:/data/NASA_biophysical/telecon_figs/' + 'hov_lon'+str(cen_lon)+'.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cen_lon=185\n",
    "ds_subset = ds_all.sel(lon=slice(cen_lon,cen_lon),lat=slice(60,50))\n",
    "tem = ds_subset.mean('time').mean('depth').drop('year')\n",
    "print(tem)\n",
    "ii = tem.argmax(dim='lat')\n",
    "ilat = tem.lat[ii.spd].data[0]\n",
    "print(ilat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cen_lon=185\n",
    "import datetime as dt\n",
    "svlat=[]\n",
    "svspd=[]\n",
    "ilon=195 #for ilon in range(195,285):\n",
    "cen_lon = ds_all.lon[ilon]\n",
    "#for this lon find the mean position\n",
    "ds_subset = ds_all.sel(lon=slice(cen_lon,cen_lon),lat=slice(60,48))\n",
    "tem = ds_subset.mean('time').mean('depth').drop('year')\n",
    "ii = tem.argmax(dim='lat')\n",
    "cen_lat = tem.lat[ii.spd].data[0]\n",
    "print(cen_lat)\n",
    "#now look around cen lat for tim variable mean \n",
    "ds_subset = ds_all.sel(time=slice(dt.datetime(2000,1,1),dt.datetime(2018,1,1)),lon=slice(cen_lon,cen_lon),lat=slice(cen_lat+2,cen_lat-4))\n",
    "tem = ds_subset.mean('depth').drop('year')\n",
    "ii = tem.argmax(dim='lat')\n",
    "yy = tem.max(dim='lat')\n",
    "cen_ii_time=ii.spd\n",
    "cen_lat_time=tem.lat[ii.spd]\n",
    "cen_lat_spd=yy.spd\n",
    "print(cen_lat_time.mean())\n",
    "cen_lat_time.plot()\n",
    "svlat.append(cen_lat_time)\n",
    "svspd.append(cen_lat_spd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem.spd[:,:,0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cen_lat_time.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all.spd[10,0,:,:].plot()\n",
    "print(ds_all.lon[195])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ilon,itime=195,180 #for ilon in range(195,285):\n",
    "cen_lon = ds_all.lon[ilon]\n",
    "ds_subset = ds_all.sel(lon=slice(cen_lon,cen_lon),lat=slice(60,47.3))\n",
    "ds_all.spd[itime,0,:,ilon].plot()\n",
    "ds_subset.spd[itime,0,:,0].plot()\n",
    "ds_smooth = ds_subset.rolling(time=4).mean()\n",
    "ds_smooth.spd[itime,0,:,0].plot()  #smooth data\n",
    "tem = ds_subset.mean('time').mean('depth').drop('year')\n",
    "ii = tem.argmax(dim='lat')\n",
    "cen_lat = tem.lat[ii.spd].data[0]\n",
    "cen_spd = tem.spd[ii.spd].data[0]\n",
    "plt.plot(cen_lat,cen_spd,'b.')\n",
    "print(cen_lat,cen_spd)\n",
    "#now look around cen lat for tim variable mean \n",
    "ds_subset = ds_all.sel(time=slice(dt.datetime(2000,1,1),dt.datetime(2018,1,1)),lon=slice(cen_lon,cen_lon),lat=slice(cen_lat+2,cen_lat-4))\n",
    "tem = ds_subset.mean('depth').drop('year')\n",
    "ii = tem.argmax(dim='lat')\n",
    "yy = tem.max(dim='lat')\n",
    "cen_ii_time=ii.spd\n",
    "cen_lat_time=tem.lat[ii.spd]\n",
    "cen_lat_spd=yy.spd\n",
    "#print(cen_lat_time)\n",
    "print(cen_lat_time.mean())\n",
    "#cen_lat_time.plot()\n",
    "plt.plot(cen_lat_time.mean(),cen_lat_spd.mean(),'r.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cen_lat_time[10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilon=195\n",
    "cen_lon = ds_all.lon[ilon]\n",
    "#for this lon find the mean position\n",
    "ds_subset = ds_all.sel(lon=slice(cen_lon,cen_lon),lat=slice(60,48))\n",
    "ds_subset.spd[86,0,:,0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_subset.spd[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,1,figsize=(4,4))\n",
    "ds_subset = ds_all.sel(lon=slice(180,180),lat=slice(65,45))\n",
    "ds_subset.spd[:,0,:,:].transpose().plot(vmin=0,vmax=.3)\n",
    "fig.savefig('F:/data/NASA_biophysical/telecon_figs/' + 'hov_lon180.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,1,figsize=(4,4))\n",
    "ds_subset = ds_all.sel(lon=slice(190,190),lat=slice(65,45))\n",
    "ds_subset.spd[:,0,:,:].transpose().plot(vmin=0,vmax=.3)\n",
    "fig.savefig('F:/data/NASA_biophysical/telecon_figs/' + 'hov_lon190.png', dpi=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,1,figsize=(4,4))\n",
    "ds_subset = ds_all.sel(lon=slice(200,200),lat=slice(65,45))\n",
    "ds_subset.spd[:,0,:,:].transpose().plot(vmin=0,vmax=.3)\n",
    "fig.savefig('F:/data/NASA_biophysical/telecon_figs/' + 'hov_lon200.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,1,figsize=(4,4))\n",
    "ds_subset = ds_all.sel(lon=slice(210,210),lat=slice(65,45))\n",
    "ds_subset.spd[:,0,:,:].transpose().plot(vmin=0,vmax=.3)\n",
    "fig.savefig('F:/data/NASA_biophysical/telecon_figs/' + 'hov_lon210.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,1,figsize=(4,4))\n",
    "ds_subset = ds_all.sel(lon=slice(180,210),lat=slice(58,47.5))\n",
    "ds_subset.spd[:,0,:,:].max('lat').transpose().plot(vmin=0,vmax=0.5)\n",
    "fig.savefig('F:/data/NASA_biophysical/telecon_figs/' + 'max_spd_180_210.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,1,figsize=(4,4))\n",
    "ds_subset = ds_all.sel(lon=slice(220,245),lat=slice(42,42))\n",
    "ds_subset.spd[:,0,:,:].transpose().plot(vmin=0,vmax=.15)\n",
    "fig.savefig('F:/data/NASA_biophysical/telecon_figs/' + 'hov_lat42.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=-180))\n",
    "ds_all.spd[0,0,:,:].plot.pcolormesh(ax=ax, transform=ccrs.PlateCarree(),vmin=-1,vmax=1,cmap='seismic');\n",
    "ax.set_global(); ax.coastlines();\n",
    "ax.set_xlim(-80,70)\n",
    "ax.set_ylim(15,65)\n",
    "fig.savefig('F:/data/NASA_biophysical/telecon_figs/' + 'sample_plot.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to make movie\n",
    "ds_all\n",
    "hv.extension('bokeh')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%output holomap='scrubber'\n",
    "%%opts Image style(cmap='rainbow') plot[colorbar=True]\n",
    "%%opts Image [width=500, height=400]\n",
    "opts = dict(cmap='rainbow', colorbar=True, width=300, height=230, axiswise=True)\n",
    "hv_ds = hv.Dataset(ds_all.spd[1:150,0,:,:])\n",
    "img = hv_ds.to(hv.Image, ['lon', 'lat']).options(**opts)\n",
    "#img.options(colorbar=True, width=300, height=230, axiswise=True)\n",
    "img.redim.range(spd=(0,.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.save(img, 'Spd_half_A.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output holomap='scrubber'\n",
    "%%opts Image style(cmap='viridis') plot[colorbar=True]\n",
    "%%opts Image [width=500, height=400]\n",
    "opts = dict(cmap='rainbow', colorbar=True, width=300, height=230, axiswise=True)\n",
    "hv_ds = hv.Dataset(ds_all.spd[100:300,0,:,:])\n",
    "img = hv_ds.to(hv.Image, ['lon', 'lat']).options(**opts)\n",
    "#img.options(colorbar=True, width=300, height=230, axiswise=True)\n",
    "img.redim.range(spd=(0,.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.save(img, 'Spd_half_B.html', backend='bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('matplotlib')\n",
    "\n",
    "air = xr.tutorial.load_dataset('air_temperature')\n",
    "ds = hv.Dataset(air.isel(time=range(100)))\n",
    "images = ds.to(hv.Image, ['lon', 'lat']).options(fig_inches=(10, 5), colorbar=True, cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y, X = np.meshgrid(ds.latitude, ds.longitude)\n",
    "#ds = ds.sel(longitude=slice(110,250),latitude=slice(65,15))\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as colors\n",
    "for imon in range (5,6): #13):\n",
    "    #ds = ds.sel(lon=slice(110,250),lat=slice(65,15))\n",
    "    X = ds.lon.values\n",
    "    Y = ds.lat.values\n",
    "    U = ds.u[imon,0,:,:]\n",
    "    V = ds.v[imon,0,:,:]\n",
    "    speed = np.sqrt(U*U + V*V)\n",
    "    speed = speed.fillna(0)\n",
    "    lws = 10*speed / speed.max()\n",
    "\n",
    "    fig0, ax0 = plt.subplots()\n",
    "    strm = ax0.streamplot(X,Y, U, V, density=6,color=V.values,linewidth=lws.values, cmap='seismic',norm=colors.Normalize(vmin=-.5,vmax=.5))\n",
    "    fig0.colorbar(strm.lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ds2 = ds.sel(lon=slice(110,179),lat=slice(65,5))\n",
    "    lons1 = ds2.lon.values\n",
    "    lons1[lons1 > 180] = lons1[lons1 > 180] - 360.  #wrap -180-180\n",
    "    lats1 = ds2.lat.values\n",
    "    \n",
    "#    lons0, lats0 = np.meshgrid(lons1,lats1)\n",
    "    X = lons1 \n",
    "    Y = lats1\n",
    "    U = ds2.u[imon,0,:,:]\n",
    "    V = ds2.v[imon,0,:,:]\n",
    "    speed = np.sqrt(U*U + V*V)\n",
    "    speed = speed.fillna(0)\n",
    "    lws = 10*speed / speed.max()\n",
    "    \n",
    "    Xg, Yg = np.meshgrid(X,Y)\n",
    "    input_projection = ccrs.PlateCarree()\n",
    "    #ax = plt.subplot(projection=output_projection)\n",
    "    #ax.streamplot(X, Y, U, V, transform=input_projection)\n",
    "#    ax0 = plt.axes(projection=ccrs.PlateCarree())\n",
    "#    ax0 = fig0.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=180.0))\n",
    "#    ax0.set_extent([-110, 110, 5, 65], crs=ccrs.PlateCarree(central_longitude=180.0))\n",
    "#    ax0.coastlines()\n",
    "\n",
    "#    fig0, ax0 = plt.subplots()\n",
    "\n",
    "    #fig0, ax0 = plt.subplots()\n",
    "    #ax0 = plt.axes(projection=ccrs.PlateCarree())\n",
    "    ax0 = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))\n",
    "    strm = ax0.streamplot(X,Y, U, V, density=6,color=V.values,linewidth=lws.values, cmap='seismic',norm=colors.Normalize(vmin=-.5,vmax=.5), transform = input_projection)\n",
    "    fig0.colorbar(strm.lines)\n",
    "\n",
    "    #fig0, ax0 = plt.figure(figsize=(10, 5))\n",
    "    #strm = ax0.streamplot(X,Y, U, V, density=6,color=V.values,linewidth=lws.values, cmap='seismic',\n",
    "    #                      norm=colors.Normalize(vmin=-.5,vmax=.5)) #, transform=input_projection)\n",
    "#    ax0.coastlines()\n",
    "#    fig0.colorbar(strm.lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Y, X = np.meshgrid(ds.latitude, ds.longitude)\n",
    "#ds = ds.sel(longitude=slice(110,250),latitude=slice(65,15))\n",
    "\n",
    "for imon in range (5,6): #13):\n",
    "    #ds = ds.sel(lon=slice(110,250),lat=slice(65,15))\n",
    "    lons1 = ds.lon.values\n",
    "    lons1[lons1 > 180] = lons1[lons1 > 180] - 360.  #wrap -180-180\n",
    "    lats1 = ds.lat.values\n",
    "    \n",
    "#    lons0, lats0 = np.meshgrid(lons1,lats1)\n",
    "    X = lons1 \n",
    "    Y = lats1\n",
    "    U = ds.u[imon,0,:,:]\n",
    "    V = ds.v[imon,0,:,:]\n",
    "    Vnorm = V/abs(V).max()\n",
    "    speed = np.sqrt(U*U + V*V)\n",
    "    speed = speed.fillna(0)\n",
    "    lws = 10*speed / speed.max()\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "#    map = Basemap(projection='cyl',llcrnrlat=lats1[-1],llcrnrlon=lons1[0],\n",
    "#                  urcrnrlat=lats1[0],urcrnrlon=lons1[-1],resolution='l')\n",
    "\n",
    "    map = Basemap(projection='lcc', llcrnrlon=110, llcrnrlat=5, \n",
    "                  urcrnrlon=-110, urcrnrlat=65,lat_0=5, lon_0=-98.)\n",
    "    map.drawcoastlines(linewidth=0.5)\n",
    "    strm = map.streamplot(X,Y, U, V, latlon=True, density=6,color=V.values,linewidth=lws.values, cmap='seismic',norm=colors.Normalize(vmin=-.5,vmax=.5))\n",
    "    #norm = mpl.colors.Normalize(vmin=-.5,vmax=.5)\n",
    "    #fig0.colorbar(strm.lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# llcrnrlat,llcrnrlon,urcrnrlat,urcrnrlon\n",
    "# are the lat/lon values of the lower left and upper right corners\n",
    "# of the map.\n",
    "# resolution = 'c' means use crude resolution coastlines.\n",
    "m = Basemap(projection='cyl',llcrnrlat=-90,urcrnrlat=90,\\\n",
    "            llcrnrlon=110,urcrnrlon=-110,resolution='c')\n",
    "m.drawcoastlines()\n",
    "m.fillcontinents(color='coral',lake_color='aqua')\n",
    "# draw parallels and meridians.\n",
    "m.drawparallels(np.arange(-90.,91.,30.))\n",
    "m.drawmeridians(np.arange(-180.,181.,60.))\n",
    "m.drawmapboundary(fill_color='aqua')\n",
    "plt.title(\"Equidistant Cylindrical Projection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xg.shape,xx.shape,yy.shape,U.shape,V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = ds.lon.values\n",
    "lons[lons > 180] = lons[lons > 180] - 360.\n",
    "lons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape,Y.shape,U.shape,V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "X = ds.lon.values\n",
    "Y = ds.lat.values\n",
    "U = ds.u[:,0,:,:]\n",
    "V = ds.v[:,0,:,:]\n",
    "Vnorm = V/abs(V).max()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#data = np.random.rand(2, 25)\n",
    "l, = ax0.streamplot(X,Y, U, V, density=6,color=Vnorm.values, linewidth=lws.values, cmap='seismic')\n",
    "line_ani = animation.FuncAnimation(fig, update_line, 25, fargs=(data, l),\n",
    "                                   interval=50, blit=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(V.min(),V.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cmap = colorbrewer.get_map('Spectral', 'diverging', 11, reverse=True).mpl_colormap\n",
    "fig = plt.figure(figsize=(11.7,8.3))\n",
    "m = Basemap(projection='merc', lat_0 = 40, lon_0 = -179, resolution = 'l', area_thresh = 0.1,\n",
    "            llcrnrlon=-110.0, llcrnrlat=25.0,urcrnrlon=-114.0, urcrnrlat=38.)\n",
    "m.bluemarble()\n",
    "lat_grid, lon_grid = np.meshgrid(ds.lat.values, ds.lon.values)\n",
    "x,y = m(lon_grid,lat_grid)\n",
    "cs = m.pcolormesh(x,y, speed.transpose(), cmap=cmap, vmin = 0, vmax = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# setup Lambert Conformal basemap.\n",
    "# set resolution=None to skip processing of boundary datasets.\n",
    "m = Basemap(width=12000000,height=9000000,projection='lcc',\n",
    "            resolution=None,lat_1=2.,lat_2=65,lat_0=50,lon_0=-110.)\n",
    "m.bluemarble(ax=None, scale=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "lats1=[-25, 66]\n",
    "lons1=[60, 179.95]\n",
    "fig=plt.figure()\n",
    "fig.set_size_inches((10, 9))\n",
    "\n",
    "ax1=fig.add_subplot(121)\n",
    "ax2=fig.add_subplot(122)\n",
    "\n",
    "bmap=Basemap(projection='merc',\\\n",
    "        llcrnrlat=lats1[0], llcrnrlon=lons1[0],\\\n",
    "        urcrnrlat=lats1[1], urcrnrlon=lons1[1],\\\n",
    "        lon_0=(lons1[0]+lons1[1])/2.,\\\n",
    "        ax=ax1)\n",
    "\n",
    "bmap.bluemarble(ax = ax1)\n",
    "\n",
    "ax1.set_position([0, 0, 0.8, 1])\n",
    "\n",
    "lats2=[-25,66]\n",
    "lons2=[-179.95, -150]\n",
    "bmap=Basemap(projection='merc',\\\n",
    "        llcrnrlat=lats2[0], llcrnrlon=lons2[0],\\\n",
    "        urcrnrlat=lats2[1], urcrnrlon=lons2[1],\\\n",
    "        lon_0=(lons2[0]+lons2[1])/2.,\\\n",
    "        ax=ax2)\n",
    "\n",
    "bmap.bluemarble(ax = ax2)\n",
    "ax2.set_position([0.8, 0, 0.2, 1])\n",
    "\n",
    "ax1.set_aspect('auto')\n",
    "ax2.set_aspect('auto')\n",
    "\n",
    "ax1.set_adjustable('datalim')\n",
    "ax2.set_adjustable('datalim')\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.u[0,0,:,:].plot()\n",
    "ds.u[0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make monthly climatology, need to drop 'year' coordinate value for mean to work right\n",
    "for lyr in range(1993,2019):\n",
    "    filename = dir_data + str(lyr) + 'monthly_data_oscar.nc'\n",
    "    ds=xr.open_dataset(filename)\n",
    "    ds2 = ds.drop('year')\n",
    "    if lyr==1993:\n",
    "        ds_clim = ds2\n",
    "    else:\n",
    "        ds_clim = xr.concat([ds_clim,ds2],dim = 'time')\n",
    "    ds.close()\n",
    "ds_clim2 = ds_clim.groupby('time.month').mean('time')\n",
    "ds_clim2.to_netcdf(dir_data + 'climatology_1993_2018_monthly_data_oscar.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make monthly climatology, need to drop 'year' coordinate value for mean to work right\n",
    "for lyr in range(2000,2019):\n",
    "    filename = dir_data + str(lyr) + 'monthly_data_oscar.nc'\n",
    "    ds=xr.open_dataset(filename)\n",
    "    ds2 = ds.drop('year')\n",
    "    if lyr==2000:\n",
    "        ds_clim = ds2\n",
    "    else:\n",
    "        ds_clim = xr.concat([ds_clim,ds2],dim = 'time')\n",
    "    ds.close()\n",
    "ds_clim2 = ds_clim.groupby('time.month').mean('time')\n",
    "ds_clim2.to_netcdf(dir_data + 'climatology_2000_2018_monthly_data_oscar.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD OLD OLD OLD OLD OLD CODE\n",
    "#make oscar climatology, OLD version of code\n",
    "#dir_data='F:/data/sat_data/oscar/L4/oscar_third_deg/'\n",
    "dir_clim='F:/data/sat_data/oscar/L4/oscar_third_deg/climatology/'\n",
    "dir_data = 'https://podaac-opendap.jpl.nasa.gov/opendap/allData/oscar/preview/L4/oscar_third_deg/'\n",
    "for lyr in range(1993,2018):\n",
    "    filename = dir_data + 'oscar_vel' + str(lyr).zfill(4) + '.nc.gz'\n",
    "    ds=xr.open_dataset(filename,drop_variables=['um','vm'])\n",
    "    ds_count=data_ones(ds)\n",
    "    #in order to add up the data the time arrays have to be aligned otherwise xarray doesn't know what to do with it\n",
    "    ds['time'] = ds['time'] - np.datetime64(lyr,'Y')\n",
    "    ds_count['time'] = ds_count['time'] - np.datetime64(lyr,'Y')\n",
    "    if lyr==1993:\n",
    "        ds2=ds.fillna(0)\n",
    "        ds_count2=ds_count.fillna(0)\n",
    "        ds_summer=ds2\n",
    "        ds_counter = ds_count2\n",
    "    else:\n",
    "        ds2 = ds.interp_like(ds_summer.time)\n",
    "        ds_count2 = ds_count.interp_like(ds_summer.time)\n",
    "        ds2=ds2.fillna(0)\n",
    "        ds_count2=ds_count2.fillna(0)\n",
    "        ds_summer=ds_summer + ds2\n",
    "        ds_counter = ds_counter + ds_count2\n",
    "    print(lyr)\n",
    "    print(ds.u.shape)\n",
    "    print(ds_summer.u.shape)\n",
    "   # print(ds_counter.u.shape)\n",
    "   # print(ds.u.shape)\n",
    "   # print(ds.time.data[0:20])\n",
    "ds_ave = ds_summer / ds_counter\n",
    "ds_ave.to_netcdf(dir_clim + 'oscar_v2009_1993_2016_climatology_12202118.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "tem_date=dt.datetime(2016,1,15)\n",
    "print(tem_date)\n",
    "filename = 'https://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/godas/dbss_obml.2016.nc'\n",
    "#filename = 'F:/data/model_data/godas/dbss_obml.2017.nc'\n",
    "ds = xr.open_dataset(filename)\n",
    "ds_storm = ds.interp(time = tem_date)\n",
    "ds_storm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            dir_ccmp='F:/data/sat_data/ccmp/v02.0/Y'\n",
    "            storm_date = dt.datetime(2015,1,1)\n",
    "            syr, smon, sdym, sjdy=str(storm_date.year),str(storm_date.month),str(storm_date.day),str(storm_date.timetuple().tm_yday)\n",
    "            fname_tem='/CCMP_Wind_Analysis_' + syr + smon.zfill(2) + sdym.zfill(2) + '_V02.0_L3.0_RSS.nc'\n",
    "            ccmp_filename = dir_ccmp + syr + '/M' + smon.zfill(2) + fname_tem      \n",
    "            ds=xr.open_dataset(ccmp_filename,drop_variables=['nobs'])\n",
    "            ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_storm.dbss_obml.plot(vmin=0,vmax=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_storm.dbss_obml[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
