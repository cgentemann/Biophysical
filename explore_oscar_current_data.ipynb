{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from palettable import colorbrewer\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as colors\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.examples.arrows import sample_data\n",
    "#for movie\n",
    "import holoviews as hv\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "from palettable import colorbrewer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#climatology\n",
    "dir_data = 'F:/data/sat_data/oscar/L4/oscar_third_deg/'\n",
    "filename = dir_data + 'climatology_1993_2018_monthly_data_oscar.nc'\n",
    "ds=xr.open_dataset(filename)\n",
    "ds.close()\n",
    "ds = ds.sel(lon=slice(110,250),lat=slice(65,5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dimensions or multi-index levels ['longitude', 'latitude'] do not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2fc931ff52bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'spd'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mds_subset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlongitude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m110\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m65\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlyr\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1993\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\xarray\\core\\dataset.py\u001b[0m in \u001b[0;36msel\u001b[1;34m(self, indexers, method, tolerance, drop, **indexers_kwargs)\u001b[0m\n\u001b[0;32m   1608\u001b[0m         \u001b[0mindexers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meither_dict_or_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexers_kwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1609\u001b[0m         pos_indexers, new_indexes = remap_label_indexers(\n\u001b[1;32m-> 1610\u001b[1;33m             self, indexers=indexers, method=method, tolerance=tolerance)\n\u001b[0m\u001b[0;32m   1611\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_indexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1612\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_replace_indexes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_indexes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\xarray\\core\\coordinates.py\u001b[0m in \u001b[0;36mremap_label_indexers\u001b[1;34m(obj, indexers, method, tolerance, **indexers_kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     pos_indexers, new_indexes = indexing.remap_label_indexers(\n\u001b[1;32m--> 355\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_indexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m     )\n\u001b[0;32m    357\u001b[0m     \u001b[1;31m# attach indexer's coordinate to pos_indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\xarray\\core\\indexing.py\u001b[0m in \u001b[0;36mremap_label_indexers\u001b[1;34m(data_obj, indexers, method, tolerance)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[0mnew_indexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m     \u001b[0mdim_indexers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_dim_indexers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim_indexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\xarray\\core\\indexing.py\u001b[0m in \u001b[0;36mget_dim_indexers\u001b[1;34m(data_obj, indexers)\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minvalid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         raise ValueError(\"dimensions or multi-index levels %r do not exist\"\n\u001b[1;32m--> 213\u001b[1;33m                          % invalid)\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[0mlevel_indexers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: dimensions or multi-index levels ['longitude', 'latitude'] do not exist"
     ]
    }
   ],
   "source": [
    "#5-day data\n",
    "dir_data = 'F:/data/sat_data/oscar/L4/oscar_third_deg/'\n",
    "for lyr in range(1993,2018): #2019): #2017):\n",
    "    filename = dir_data + 'oscar_vel' + str(lyr).zfill(4) + '.nc'\n",
    "    ds=xr.open_dataset(filename,drop_variables=['um','vm'])\n",
    "   # ds = ds.rename({'longitude':'lon','latitude':'lat'})\n",
    "    ds = ds.drop('year')\n",
    "    ds['spd']=np.sqrt(ds.u*ds.u+ds.v*ds.v)\n",
    "    ds_subset = ds.sel(longitude=slice(110,250),latitude=slice(65,0))\n",
    "    ds.close()\n",
    "    if lyr==1993:\n",
    "        ds_all = ds_subset\n",
    "    else:\n",
    "        ds_all=xr.concat([ds_all,ds_subset],'time')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put 5 day data into one big array or next section is for monthly (smaller)\n",
    "#I'd like to use xarray open_mfdataset rather than loop over all the files but the files are not\n",
    "#formatted correctly.  there is both year and time for some reason and it confuses the concat.\n",
    "#put monthly data into one big array\n",
    "#dir_data = 'F:/data/sat_data/oscar/L4/oscar_third_deg/*.nc'\n",
    "#ds_all2 = xr.open_mfdataset(dir_data, chunks=None, concat_dim='time')\n",
    "#ds_all2 = ds_all2.sel(depth=15)\n",
    "\n",
    "#so instead, let's loop....\n",
    "\n",
    "#put monthly data into one big array\n",
    "dir_data = 'F:/data/sat_data/oscar/L4/oscar_third_deg/'\n",
    "for lyr in range(1993,2018): #2019): #2017):\n",
    "    filename = dir_data + str(lyr) + 'monthly_data_oscar.nc'\n",
    "    ds=xr.open_dataset(filename)\n",
    "    ds_subset = ds.sel(lon=slice(120,250),lat=slice(65,15))\n",
    "    ds.close()\n",
    "    if lyr==1993:\n",
    "        ds_all = ds_subset\n",
    "    else:\n",
    "        ds_all=xr.concat([ds_all,ds_subset],'time')\n",
    "ds_all = ds_all.sel(depth=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a lank mask for the oscar data\n",
    "ds=xr.open_dataset('F:/data/sst/cmc/CMC0.2deg/v2/2012/004/20120104120000-CMC-L4_GHRSST-SSTfnd-CMC0.2deg-GLOB-v02.0-fv02.0.nc')\n",
    "ds.close()\n",
    "ds = ds.mask.isel(time=0)\n",
    "ds.coords['lon'] = np.mod(ds['lon'], 360)\n",
    "ds = ds.sortby(ds.lon)\n",
    "landmask = ds.interp_like(ds_all,method='nearest')\n",
    "landmask.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all['mask']=landmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,1,figsize=(4,4))\n",
    "ds_all.spd[0,:,:].plot(vmin=0,vmax=.3)\n",
    "fig.savefig('F:/data/NASA_biophysical/telecon_figs/' + 'map.png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11.7,8.3))\n",
    "ds_subset = ds_all.sel(lon=slice(180,225),lat=slice(65,40))\n",
    "ds_subset.coords['lon'] = (ds_subset.coords['lon'] + 180) % 360 - 180\n",
    "m = Basemap(projection='merc', lat_0 = 50, lon_0 = -175,    resolution = 'l', area_thresh = 0.1,\n",
    "            llcrnrlon=-175, llcrnrlat=40,urcrnrlon=-135, urcrnrlat=65)\n",
    "m.bluemarble()\n",
    "#    m.fillcontinents(color='grey',lake_color='white')\n",
    "lon_grid, lat_grid = np.meshgrid(ds_subset.lon, ds_subset.lat)\n",
    "x,y = m(lon_grid,lat_grid)\n",
    "cs = m.pcolormesh(x,y, ds_subset.spd[120,:,:], cmap='jet', vmin = 0, vmax = .5)\n",
    "m.colorbar(label='Current Velocity (ms$^{-1}$)')\n",
    "fig.savefig('F:/data/NASA_biophysical/telecon_figs/current_speed_image_2003.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_subset = ds_all.sel(lon=slice(120,250),lat=slice(65,40))\n",
    "ds_subset.coords['lon'] = (ds_subset.coords['lon'] + 180) % 360 - 180\n",
    "plt.figure(figsize=(13,6.2))\n",
    "ax = plt.subplot(111, projection=ccrs.Mercator(central_longitude=180, \n",
    "                                               min_latitude=40, max_latitude=65))\n",
    "ax.background_img(name='ne_shaded', resolution='low')\n",
    "#ax.background_img(name='BM', resolution='high')\n",
    "ax.set_extent([130,-122,40,65])\n",
    "mm = ax.pcolormesh(ds_subset.lon,ds_subset.lat,ds_subset.spd[120,:,:],vmin=0, vmax=.5, transform=ccrs.PlateCarree(),cmap='jet' )\n",
    "ax.coastlines(resolution='10m');\n",
    "plt.title(str(ds_subset.time[120].data))\n",
    "plt.colorbar(mm,ax=ax,shrink=.7,pad=.01,label='Current Velocity (ms$^{-1}$)')\n",
    "fig.savefig('F:/data/NASA_biophysical/telecon_figs/map_NPac_day20030131.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot mean and std\n",
    "ds_subset = ds_all.sel(lon=slice(165,240),lat=slice(62,40))\n",
    "plt.subplots(1,1,figsize=(13,6.2))\n",
    "#fig, axarr = plt.subplots(1,1,figsize=(12,3.5))\n",
    "gs1 = gridspec.GridSpec(1, 2)\n",
    "ax = plt.subplot(gs1[0],projection=ccrs.Mercator(central_longitude=180,min_latitude=48, max_latitude=62))\n",
    "ax.background_img(name='ne_shaded', resolution='low')\n",
    "#ax.background_img(name='BM', resolution='high')\n",
    "ax.set_extent([165,-122,40,62])\n",
    "mm = ax.pcolormesh(ds_subset.lon,ds_subset.lat,ds_subset.spd.mean('time'),vmin=0, vmax=.15, transform=ccrs.PlateCarree(),cmap='viridis' )\n",
    "ax.coastlines(resolution='10m');\n",
    "plt.title('Current Velocity')\n",
    "plt.colorbar(mm,ax=ax,shrink=.3,pad=.01,label='Mean(ms$^{-1}$)')\n",
    "\n",
    "ax = plt.subplot(gs1[1],projection=ccrs.Mercator(central_longitude=180,min_latitude=48, max_latitude=62))\n",
    "ax.background_img(name='ne_shaded', resolution='low')\n",
    "#ax.background_img(name='BM', resolution='high')\n",
    "ax.set_extent([165,-122,40,62])\n",
    "mm = ax.pcolormesh(ds_subset.lon,ds_subset.lat,ds_subset.spd.std('time'),vmin=0, vmax=.06, transform=ccrs.PlateCarree(),cmap='viridis' )\n",
    "ax.coastlines(resolution='10m');\n",
    "plt.title('Current Velocity')\n",
    "plt.colorbar(mm,ax=ax,shrink=.3,pad=.01,label='STD (ms$^{-1}$)')\n",
    "\n",
    "#,projection=ccrs.PlateCarree(central_longitude=icenter))\n",
    "#ax.pcolormesh(ds_subset.lon,ds_subset.lat,ds_subset.spd.mean('time'),vmin=0,vmax=.2)\n",
    "#plt.plot(ds_subset.lon,ds_subset.lat[curr_max_location],'r',markersize=2)\n",
    "#ax = plt.subplot(gs1[1])\n",
    "#ax.pcolormesh(ds_subset.lon,ds_subset.lat,ds_subset.spd.std('time'),vmin=0,vmax=.05)\n",
    "#plt.plot(ds_subset.lon,ds_subset.lat[curr_max_location],'r',markersize=2)\n",
    "#plt.plot(ds_subset.lon,ds_subset.lat[curr_max_location-2],'k',markersize=2)\n",
    "#plt.plot(ds_subset.lon,ds_subset.lat[lower_boundary_index+1],'k',markersize=2)\n",
    "plt.savefig('F:/data/NASA_biophysical/telecon_figs/mean_std_current_speed.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_subset = ds_all.sel(lon=slice(165,228),lat=slice(62,48))\n",
    "#ds_subset.coords['lon'] = (ds_subset.coords['lon'] + 180) % 360 - 180\n",
    "#ds_subset = ds_subset.sortby(ds_subset.lon)\n",
    "ax = plt.subplot(gs1[0],projection=ccrs.Mercator(central_longitude=180,min_latitude=48, max_latitude=62))\n",
    "ax.background_img(name='ne_shaded', resolution='low')\n",
    "ax.set_extent([165,-122,48,62])\n",
    "#xlon=ds_subset.lon.copy(deep=True); xlon[xlon>180]-=360\n",
    "#mm = ax.pcolormesh(ds_subset.lon,ds_subset.lat,ds_subset.spd.mean('time'),vmin=0, vmax=.2, transform=ccrs.PlateCarree(),cmap='viridis' )\n",
    "ax.plot(ds_subset.lon,ds_subset.lat[curr_max_location],'r.',linewidth=20,markersize=10, transform=ccrs.PlateCarree())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_subset = ds_all.sel(lon=slice(165,228),lat=slice(61,48))\n",
    "#ds_subset.coords['lon'] = (ds_subset.coords['lon'] + 180) % 360 - 180\n",
    "#ds_subset = ds_subset.sortby(ds_subset.lon)\n",
    "curr_mean = ds_subset.spd.mean('time')\n",
    "curr_mean2=curr_mean.where((curr_mean.lon<180) & (curr_mean.lat<53) | (curr_mean.lon>180) & (curr_mean.lat<62))\n",
    "#i don't understand why but the where above which is just to mask out the arctic ocean area for some\n",
    "#reason sets the 180 longitude to zero so I reset it to the values manually\n",
    "curr_mean2[:,45]=curr_mean[:,45]\n",
    "curr_max = curr_mean2.max('lat')\n",
    "curr_max_location = np.argmax(curr_mean2,0)\n",
    "curr_std = ds_subset.spd.std('time')\n",
    "cmask = curr_std.where(curr_std>=0.048)\n",
    "[lon2d,lat2d]=np.meshgrid(cmask.lon,cmask.lat)\n",
    "lat2dm = np.where(np.isnan(cmask), lat2d*np.nan,lat2d)\n",
    "lower_boundary = np.nanmin(lat2dm,0)\n",
    "lower_boundary_index = np.nanargmin(lat2dm,0)\n",
    "plt.subplots(1,1,figsize=(13,6.2))\n",
    "#fig, axarr = plt.subplots(1,1,figsize=(12,3.5))\n",
    "gs1 = gridspec.GridSpec(1, 2)\n",
    "ax = plt.subplot(gs1[0],projection=ccrs.Mercator(central_longitude=180,min_latitude=48, max_latitude=62))\n",
    "ax.background_img(name='ne_shaded', resolution='low')\n",
    "#ax.background_img(name='BM', resolution='high')\n",
    "ax.set_extent([165,-122,48,62])\n",
    "mm = ax.pcolormesh(ds_subset.lon,ds_subset.lat,ds_subset.spd.mean('time'),vmin=0, vmax=.2, transform=ccrs.PlateCarree(),cmap='viridis' )\n",
    "ax.plot(ds_subset.lon,ds_subset.lat[curr_max_location],'r',markersize=2,linewidth=2, transform=ccrs.PlateCarree())\n",
    "ax.coastlines(resolution='10m');\n",
    "#plt.title(str(ds_subset.time[120].data))\n",
    "plt.colorbar(mm,ax=ax,shrink=.3,pad=.01,label='Current Velocity Mean(ms$^{-1}$)')\n",
    "\n",
    "ax = plt.subplot(gs1[1],projection=ccrs.Mercator(central_longitude=180,min_latitude=48, max_latitude=62))\n",
    "ax.background_img(name='ne_shaded', resolution='low')\n",
    "#ax.background_img(name='BM', resolution='high')\n",
    "ax.set_extent([165,-122,48,62])\n",
    "mm = ax.pcolormesh(ds_subset.lon,ds_subset.lat,ds_subset.spd.std('time'),vmin=0, vmax=.05, transform=ccrs.PlateCarree(),cmap='viridis' )\n",
    "ax.plot(ds_subset.lon,ds_subset.lat[curr_max_location],'r',markersize=2,linewidth=2, transform=ccrs.PlateCarree())\n",
    "ax.plot(ds_subset.lon,ds_subset.lat[curr_max_location-2],'k',markersize=2,linewidth=2, transform=ccrs.PlateCarree())\n",
    "ax.plot(ds_subset.lon,ds_subset.lat[lower_boundary_index],'k',markersize=2,linewidth=2, transform=ccrs.PlateCarree())\n",
    "ax.coastlines(resolution='10m');\n",
    "#plt.title(str(ds_subset.time[120].data))\n",
    "plt.colorbar(mm,ax=ax,shrink=.3,pad=.01,label='Current Velocity STD (ms$^{-1}$)')\n",
    "plt.savefig('F:/data/NASA_biophysical/telecon_figs/mean_std_current_speed_mask.png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a mask usin the upper and lower limits\n",
    "ds_subset['mask_alaskan_stream']=ds_subset['spd'].copy(deep=True)*np.nan\n",
    "print(ds_subset.mask_alaskan_stream.shape)\n",
    "for i in range(0,ds_subset.lon.size):\n",
    "    l1=lower_boundary_index[i].astype(int)\n",
    "    l2=curr_max_location[i].astype(int).data-2\n",
    "    #print(l1,l2)\n",
    "    ds_subset['mask_alaskan_stream'][:,0:l2+1,i]=1\n",
    "    ds_subset['mask_alaskan_stream'][:,l1:,i]=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "ds_masked = ds_subset.where(np.isnan(ds_subset.mask_alaskan_stream))  #this will mask out all data \n",
    "curr_max = ds_masked.spd.max('lat')\n",
    "curr_max.attrs={'standard_name':'current velocity (cm/s)'}\n",
    "curr_max.plot(vmin=0,vmax=0.5,cmap='seismic')\n",
    "plt.savefig('F:/data/NASA_biophysical/telecon_figs/max_curr_AS_hovmuller.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove annual cycle\n",
    "climatology = curr_max.groupby('time.month').mean('time')\n",
    "anomalies = curr_max.groupby('time.month') - climatology\n",
    "anomalies.attrs={'standard_name':'current velocity seasonal cycle removed(cm/s)'}\n",
    "anomalies.plot(vmin=-0.2,vmax=0.2,cmap='jet')\n",
    "plt.savefig('F:/data/NASA_biophysical/telecon_figs/max_curr_AS_hovmuller_seasonal_cycle_removed.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_masked = ds_subset.where(np.isnan(ds_subset.mask_alaskan_stream))  #this will mask out all data \n",
    "ds_filled = ds_subset.fillna(0)  #problem for early data where over land masking produces lots of missing data\n",
    "curr_max = ds_filled.spd.max('lat')\n",
    "curr_max_location_time = np.nanargmax(ds_filled.spd,1)  #find the time of the max\n",
    "plt.pcolormesh(ds_filled.lon,ds_filled.time,curr_max) #,vmin=5,vmax=33)\n",
    "#plt.pcolormesh(ds_filled.lon,ds_filled.time,curr_max_location,vmin=5,vmax=33)\n",
    "plt.colorbar(label='index latitude of current maximum')\n",
    "plt.savefig('F:/data/NASA_biophysical/telecon_figs/max_curr_latitude_index.png', dpi=100)\n",
    "\n",
    "#find distance from mean location to look at variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_max_location.shape\n",
    "print(curr_max_location.shape)\n",
    "print(curr_max_location_time.shape)\n",
    "ds_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#caluclate distance from mean location of AS at each longitude and time\n",
    "import geopy.distance\n",
    "curr_var = np.zeros((300,ds_subset.lon.size))\n",
    "for t in range(0,300):\n",
    "    for i in range(0,ds_subset.lon.size):\n",
    "        s = np.sign(ds_subset.lat[curr_max_location[i]].data-ds_subset.lat[curr_max_location_time[t,i]].data)\n",
    "        coords_1 = (ds_subset.lat[curr_max_location[i]],ds_subset.lon[i])  \n",
    "        coords_2 = (ds_subset.lat[curr_max_location_time[t,i]],ds_subset.lon[i])  \n",
    "        curr_var[t,i] = s*geopy.distance.geodesic(coords_1, coords_2).km  #distance in km  \n",
    "ds_tem = xr.DataArray(curr_var,coords={'time': ds_subset.time,'lon':ds_subset.lon}, dims=('time', 'lon'))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(ds_subset.lon,ds_subset.time,curr_var,vmin=-200,vmax=200,cmap='seismic')\n",
    "plt.xlabel('Longitude (deg)')\n",
    "plt.ylabel('Date')\n",
    "plt.colorbar(label='distance from mean location (km)')\n",
    "plt.savefig('F:/data/NASA_biophysical/telecon_figs/max_curr_distance_from_mean.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=100\n",
    "np.sign(ds_subset.lat[curr_max_location[i]].data-ds_subset.lat[curr_max_location_time[t,i]].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_vel = ds_tem.sel(lon=slice(190,208),time=slice('2000-01-01','2016-12-31'))\n",
    "subset_vel.plot(vmin=-500,vmax=500,cmap='seismic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at region and mask out edges so can fit a line better\n",
    "subset_vel = ds_tem.sel(lon=slice(190,210),time=slice('2002-07-01','2005-01-31'))\n",
    "subset_vel = subset_vel.where((subset_vel.time<np.datetime64('2003-10')) | (subset_vel.lon<200))\n",
    "subset_vel = subset_vel.where((subset_vel.time>np.datetime64('2003-07')) | (subset_vel.lon>198))\n",
    "subset_vel.plot(vmin=-100,vmax=100,cmap='seismic')\n",
    "plt.plot([210,190],[np.datetime64('2002-07'),np.datetime64('2004-09')],'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svfitx,svfity,svfits,svfitp=np.zeros((5,35)),np.zeros((5,35)),np.zeros(5),np.zeros(5)\n",
    "ind = subset_vel.where(subset_vel>40, drop=True).squeeze()\n",
    "xx,yy=[],[]\n",
    "for i in range(0,ind.shape[0]):\n",
    "    for j in range(0,ind.shape[1]):\n",
    "        if np.isnan(ind[i,j]):\n",
    "            continue\n",
    "        xx,yy=np.append(xx,ind.lon[j]),np.append(yy,(ind.time[i]-ind.time[0])/np.timedelta64(1, 'D'))\n",
    "p = np.polyfit(xx,yy,1)\n",
    "xfit = np.arange(190,225,1) #(0,60,1)\n",
    "yfit = np.polyval(p,xfit)\n",
    "tax = (ind.time - ind.time[0])/np.timedelta64(1, 'D')\n",
    "plt.pcolor(ind.lon,tax,ind)\n",
    "plt.plot(xfit,yfit,'r')\n",
    "print(p)\n",
    "print(xfit[-1],(ind.time[0]+np.timedelta64(int(yfit[-1]),'D')).data)\n",
    "print('start',((ind.time[0]-np.datetime64('2000-01-01'))/np.timedelta64(1,'D')).data)\n",
    "svfitx[0,:]=xfit\n",
    "svfity[0,:]=yfit\n",
    "svfits[0]=((ind.time[0]-np.datetime64('2000-01-01'))/np.timedelta64(1,'D')).data\n",
    "svfitp[0]=p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at region and mask out edges so can fit a line better\n",
    "subset_vel = ds_tem.sel(lon=slice(190,210),time=slice('2003-10-01','2008-01-31'))\n",
    "subset_vel = subset_vel.where((subset_vel.time<np.datetime64('2006-10')) | (subset_vel.lon<195))\n",
    "subset_vel = subset_vel.where((subset_vel.time<np.datetime64('2006-07')) | (subset_vel.lon<196))\n",
    "subset_vel = subset_vel.where((subset_vel.time<np.datetime64('2005-01')) | (subset_vel.lon<207))\n",
    "subset_vel = subset_vel.where((subset_vel.time<np.datetime64('2005-07')) | (subset_vel.lon<203))\n",
    "subset_vel = subset_vel.where((subset_vel.time<np.datetime64('2005-03')) | (subset_vel.lon<205))\n",
    "subset_vel = subset_vel.where((subset_vel.time<np.datetime64('2004-07')) | (subset_vel.lon<209))\n",
    "subset_vel = subset_vel.where((subset_vel.time>np.datetime64('2005-01')) | (subset_vel.lon>203))\n",
    "subset_vel.plot(vmin=-100,vmax=100,cmap='seismic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = subset_vel.where(subset_vel>40, drop=True).squeeze()\n",
    "xx,yy=[],[]\n",
    "for i in range(0,ind.shape[0]):\n",
    "    for j in range(0,ind.shape[1]):\n",
    "        if np.isnan(ind[i,j]):\n",
    "            continue\n",
    "        xx,yy=np.append(xx,ind.lon[j]),np.append(yy,(ind.time[i]-ind.time[0])/np.timedelta64(1, 'D'))\n",
    "p = np.polyfit(xx,yy,1)\n",
    "xfit = np.arange(190,225,1) #(0,60,1)\n",
    "yfit = np.polyval(p,xfit)\n",
    "tax = (ind.time - ind.time[0])/np.timedelta64(1, 'D')\n",
    "plt.pcolor(ind.lon,tax,ind)\n",
    "plt.plot(xfit,yfit,'r')\n",
    "print(p)\n",
    "print(xfit[-1],(ind.time[0]+np.timedelta64(int(yfit[-1]),'D')).data)\n",
    "print('start',((ind.time[0]-np.datetime64('2000-01-01'))/np.timedelta64(1,'D')).data)\n",
    "svfitx[1,:]=xfit\n",
    "svfity[1,:]=yfit\n",
    "svfits[1]=((ind.time[0]-np.datetime64('2000-01-01'))/np.timedelta64(1,'D')).data\n",
    "svfitp[1]=p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at region and mask out edges so can fit a line better\n",
    "subset_vel = ds_tem.sel(lon=slice(190,210),time=slice('2006-10-01','2010-01-31'))\n",
    "subset_vel = subset_vel.where((subset_vel.time<np.datetime64('2009-02')) | (subset_vel.lon<200))\n",
    "subset_vel = subset_vel.where((subset_vel.time<np.datetime64('2008-01')) | (subset_vel.lon<205))\n",
    "subset_vel = subset_vel.where((subset_vel.time>np.datetime64('2008-04')) | (subset_vel.lon>200))\n",
    "subset_vel = subset_vel.where((subset_vel.time>np.datetime64('2007-04')) | (subset_vel.lon>205))\n",
    "subset_vel = subset_vel.where((subset_vel.time>np.datetime64('2007-03')) | (subset_vel.lon>209))\n",
    "subset_vel.plot(vmin=-100,vmax=100,cmap='seismic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = subset_vel.where(subset_vel>40, drop=True).squeeze()\n",
    "xx,yy=[],[]\n",
    "for i in range(0,ind.shape[0]):\n",
    "    for j in range(0,ind.shape[1]):\n",
    "        if np.isnan(ind[i,j]):\n",
    "            continue\n",
    "        xx,yy=np.append(xx,ind.lon[j]),np.append(yy,(ind.time[i]-ind.time[0])/np.timedelta64(1, 'D'))\n",
    "p = np.polyfit(xx,yy,1)\n",
    "xfit = np.arange(190,225,1) #(0,60,1)\n",
    "yfit = np.polyval(p,xfit)\n",
    "tax = (ind.time - ind.time[0])/np.timedelta64(1, 'D')\n",
    "plt.pcolor(ind.lon,tax,ind)\n",
    "plt.plot(xfit,yfit,'r')\n",
    "print(p)\n",
    "print(xfit[-1],(ind.time[0]+np.timedelta64(int(yfit[-1]),'D')).data)\n",
    "print('start',((ind.time[0]-np.datetime64('2000-01-01'))/np.timedelta64(1,'D')).data)\n",
    "svfitx[2,:]=xfit\n",
    "svfity[2,:]=yfit\n",
    "svfits[2]=((ind.time[0]-np.datetime64('2000-01-01'))/np.timedelta64(1,'D')).data\n",
    "svfitp[2]=p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at region and mask out edges so can fit a line better\n",
    "subset_vel = ds_tem.sel(lon=slice(190,210),time=slice('2010-01-03','2012-11-01'))\n",
    "subset_vel = subset_vel.where((subset_vel.time<np.datetime64('2011-10')) | (subset_vel.lon<200))\n",
    "subset_vel = subset_vel.where((subset_vel.time<np.datetime64('2011-01')) | (subset_vel.lon<207))\n",
    "subset_vel = subset_vel.where((subset_vel.time>np.datetime64('2010-10')) | (subset_vel.lon>205))\n",
    "subset_vel.plot(vmin=-100,vmax=100,cmap='seismic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = subset_vel.where(subset_vel>40, drop=True).squeeze()\n",
    "xx,yy=[],[]\n",
    "for i in range(0,ind.shape[0]):\n",
    "    for j in range(0,ind.shape[1]):\n",
    "        if np.isnan(ind[i,j]):\n",
    "            continue\n",
    "        xx,yy=np.append(xx,ind.lon[j]),np.append(yy,(ind.time[i]-ind.time[0])/np.timedelta64(1, 'D'))\n",
    "p = np.polyfit(xx,yy,1)\n",
    "xfit = np.arange(190,225,1) #(0,60,1)\n",
    "yfit = np.polyval(p,xfit)\n",
    "tax = (ind.time - ind.time[0])/np.timedelta64(1, 'D')\n",
    "plt.pcolor(ind.lon,tax,ind)\n",
    "plt.plot(xfit,yfit,'r')\n",
    "print(p)\n",
    "print(xfit[-1],(ind.time[0]+np.timedelta64(int(yfit[-1]),'D')).data)\n",
    "print('start',((ind.time[0]-np.datetime64('2000-01-01'))/np.timedelta64(1,'D')).data)\n",
    "svfitx[3,:]=xfit\n",
    "svfity[3,:]=yfit\n",
    "svfits[3]=((ind.time[0]-np.datetime64('2000-01-01'))/np.timedelta64(1,'D')).data\n",
    "svfitp[3]=p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_vel = ds_tem.sel(lon=slice(190,210),time=slice('2011-10-03','2014-07-01'))\n",
    "subset_vel = subset_vel.where((subset_vel.time<np.datetime64('2014-01')) | (subset_vel.lon<200))\n",
    "subset_vel = subset_vel.where((subset_vel.time<np.datetime64('2013-07')) | (subset_vel.lon<202))\n",
    "subset_vel = subset_vel.where((subset_vel.time<np.datetime64('2013-01')) | (subset_vel.lon<204))\n",
    "subset_vel = subset_vel.where((subset_vel.time>np.datetime64('2012-10')) | (subset_vel.lon>200))\n",
    "subset_vel.plot(vmin=-100,vmax=100,cmap='seismic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = subset_vel.where(subset_vel>40, drop=True).squeeze()\n",
    "xx,yy=[],[]\n",
    "for i in range(0,ind.shape[0]):\n",
    "    for j in range(0,ind.shape[1]):\n",
    "        if np.isnan(ind[i,j]):\n",
    "            continue\n",
    "        xx,yy=np.append(xx,ind.lon[j]),np.append(yy,(ind.time[i]-ind.time[0])/np.timedelta64(1, 'D'))\n",
    "p = np.polyfit(xx,yy,1)\n",
    "xfit = np.arange(190,225,1) #(0,60,1)\n",
    "yfit = np.polyval(p,xfit)\n",
    "tax = (ind.time - ind.time[0])/np.timedelta64(1, 'D')\n",
    "plt.pcolor(ind.lon,tax,ind)\n",
    "plt.plot(xfit,yfit,'r')\n",
    "print(p)\n",
    "print(xfit[-1],(ind.time[0]+np.timedelta64(int(yfit[-1]),'D')).data)\n",
    "print('start',((ind.time[0]-np.datetime64('2000-01-01'))/np.timedelta64(1,'D')).data)\n",
    "svfitx[4,:]=xfit\n",
    "svfity[4,:]=yfit\n",
    "svfits[4]=((ind.time[0]-np.datetime64('2000-01-01'))/np.timedelta64(1,'D')).data\n",
    "svfitp[4]=p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_vel = ds_tem.sel(lon=slice(165,225),time=slice('2000-01-01','2016-12-31'))\n",
    "tax = (subset_vel.time - subset_vel.time[0])/np.timedelta64(1, 'D')\n",
    "plt.pcolormesh(subset_vel.lon,tax,subset_vel,vmin=-500,vmax=500,cmap='seismic')\n",
    "for i in range(0,5):\n",
    "    plt.plot(svfitx[i,:],svfity[i,:]+svfits[i],'k',label=str(i))\n",
    "    plt.text(191,svfity[i,0]+svfits[i],str(i))\n",
    "plt.xlabel('Longitude (deg)')\n",
    "plt.ylabel('Days from 2000-01-01')\n",
    "plt.colorbar(label='Distance from mean location (km)')\n",
    "plt.savefig('F:/data/NASA_biophysical/telecon_figs/eddy_hov.png', dpi=100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svfitp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lat = np.empty(250)\n",
    "max_lat = np.empty(250)\n",
    "#max_lat[185:]=[52.0,52.1,52.1,52.1,54]\n",
    "for cen_lon in range(165,195):\n",
    "    fig, axarr = plt.subplots(1,1,figsize=(4,4))\n",
    "    ds_subset = ds_all.sel(lon=slice(cen_lon,cen_lon),lat=slice(60,50))\n",
    "    ds_subset.spd[84:,:,:].transpose().plot(vmin=0,vmax=.3)\n",
    "    fig.savefig('F:/data/NASA_biophysical/telecon_figs/' + 'hov_lon'+str(cen_lon)+'.png', dpi=100)\n",
    "    fig.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cen_lon=185\n",
    "ds_subset = ds_all.sel(lon=slice(cen_lon,cen_lon),lat=slice(60,50))\n",
    "tem = ds_subset.mean('time').mean('depth').drop('year')\n",
    "print(tem)\n",
    "ii = tem.argmax(dim='lat')\n",
    "ilat = tem.lat[ii.spd].data[0]\n",
    "print(ilat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cen_lon=185\n",
    "import datetime as dt\n",
    "svlat=[]\n",
    "svspd=[]\n",
    "ilon=195 #for ilon in range(195,285):\n",
    "cen_lon = ds_all.lon[ilon]\n",
    "#for this lon find the mean position\n",
    "ds_subset = ds_all.sel(lon=slice(cen_lon,cen_lon),lat=slice(60,48))\n",
    "tem = ds_subset.mean('time').mean('depth').drop('year')\n",
    "ii = tem.argmax(dim='lat')\n",
    "cen_lat = tem.lat[ii.spd].data[0]\n",
    "print(cen_lat)\n",
    "#now look around cen lat for tim variable mean \n",
    "ds_subset = ds_all.sel(time=slice(dt.datetime(2000,1,1),dt.datetime(2018,1,1)),lon=slice(cen_lon,cen_lon),lat=slice(cen_lat+2,cen_lat-4))\n",
    "tem = ds_subset.mean('depth').drop('year')\n",
    "ii = tem.argmax(dim='lat')\n",
    "yy = tem.max(dim='lat')\n",
    "cen_ii_time=ii.spd\n",
    "cen_lat_time=tem.lat[ii.spd]\n",
    "cen_lat_spd=yy.spd\n",
    "print(cen_lat_time.mean())\n",
    "cen_lat_time.plot()\n",
    "svlat.append(cen_lat_time)\n",
    "svspd.append(cen_lat_spd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem.spd[:,:,0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cen_lat_time.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all.spd[10,0,:,:].plot()\n",
    "print(ds_all.lon[195])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ilon,itime=195,180 #for ilon in range(195,285):\n",
    "cen_lon = ds_all.lon[ilon]\n",
    "ds_subset = ds_all.sel(lon=slice(cen_lon,cen_lon),lat=slice(60,47.3))\n",
    "ds_all.spd[itime,0,:,ilon].plot()\n",
    "ds_subset.spd[itime,0,:,0].plot()\n",
    "ds_smooth = ds_subset.rolling(time=4).mean()\n",
    "ds_smooth.spd[itime,0,:,0].plot()  #smooth data\n",
    "tem = ds_subset.mean('time').mean('depth').drop('year')\n",
    "ii = tem.argmax(dim='lat')\n",
    "cen_lat = tem.lat[ii.spd].data[0]\n",
    "cen_spd = tem.spd[ii.spd].data[0]\n",
    "plt.plot(cen_lat,cen_spd,'b.')\n",
    "print(cen_lat,cen_spd)\n",
    "#now look around cen lat for tim variable mean \n",
    "ds_subset = ds_all.sel(time=slice(dt.datetime(2000,1,1),dt.datetime(2018,1,1)),lon=slice(cen_lon,cen_lon),lat=slice(cen_lat+2,cen_lat-4))\n",
    "tem = ds_subset.mean('depth').drop('year')\n",
    "ii = tem.argmax(dim='lat')\n",
    "yy = tem.max(dim='lat')\n",
    "cen_ii_time=ii.spd\n",
    "cen_lat_time=tem.lat[ii.spd]\n",
    "cen_lat_spd=yy.spd\n",
    "#print(cen_lat_time)\n",
    "print(cen_lat_time.mean())\n",
    "#cen_lat_time.plot()\n",
    "plt.plot(cen_lat_time.mean(),cen_lat_spd.mean(),'r.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cen_lat_time[10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilon=195\n",
    "cen_lon = ds_all.lon[ilon]\n",
    "#for this lon find the mean position\n",
    "ds_subset = ds_all.sel(lon=slice(cen_lon,cen_lon),lat=slice(60,48))\n",
    "ds_subset.spd[86,0,:,0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_subset.spd[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,1,figsize=(4,4))\n",
    "ds_subset = ds_all.sel(lon=slice(180,180),lat=slice(65,45))\n",
    "ds_subset.spd[:,0,:,:].transpose().plot(vmin=0,vmax=.3)\n",
    "fig.savefig('F:/data/NASA_biophysical/telecon_figs/' + 'hov_lon180.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,1,figsize=(4,4))\n",
    "ds_subset = ds_all.sel(lon=slice(190,190),lat=slice(65,45))\n",
    "ds_subset.spd[:,0,:,:].transpose().plot(vmin=0,vmax=.3)\n",
    "fig.savefig('F:/data/NASA_biophysical/telecon_figs/' + 'hov_lon190.png', dpi=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,1,figsize=(4,4))\n",
    "ds_subset = ds_all.sel(lon=slice(200,200),lat=slice(65,45))\n",
    "ds_subset.spd[:,0,:,:].transpose().plot(vmin=0,vmax=.3)\n",
    "fig.savefig('F:/data/NASA_biophysical/telecon_figs/' + 'hov_lon200.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,1,figsize=(4,4))\n",
    "ds_subset = ds_all.sel(lon=slice(210,210),lat=slice(65,45))\n",
    "ds_subset.spd[:,0,:,:].transpose().plot(vmin=0,vmax=.3)\n",
    "fig.savefig('F:/data/NASA_biophysical/telecon_figs/' + 'hov_lon210.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,1,figsize=(4,4))\n",
    "ds_subset = ds_all.sel(lon=slice(180,210),lat=slice(58,47.5))\n",
    "ds_subset.spd[:,0,:,:].max('lat').transpose().plot(vmin=0,vmax=0.5)\n",
    "fig.savefig('F:/data/NASA_biophysical/telecon_figs/' + 'max_spd_180_210.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,1,figsize=(4,4))\n",
    "ds_subset = ds_all.sel(lon=slice(220,245),lat=slice(42,42))\n",
    "ds_subset.spd[:,0,:,:].transpose().plot(vmin=0,vmax=.15)\n",
    "fig.savefig('F:/data/NASA_biophysical/telecon_figs/' + 'hov_lat42.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=-180))\n",
    "ds_all.spd[0,0,:,:].plot.pcolormesh(ax=ax, transform=ccrs.PlateCarree(),vmin=-1,vmax=1,cmap='seismic');\n",
    "ax.set_global(); ax.coastlines();\n",
    "ax.set_xlim(-80,70)\n",
    "ax.set_ylim(15,65)\n",
    "fig.savefig('F:/data/NASA_biophysical/telecon_figs/' + 'sample_plot.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a movie of the monthly images\n",
    "#would like to plot mean location, monthly locations, eddies\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.rcParams['animation.ffmpeg_path'] = 'c:/FFmpeg/bin/'\n",
    "plt.rcParams['animation.ffmpeg_path'] ='C:\\\\FFmpeg\\\\bin\\\\ffmpeg.exe'\n",
    "import matplotlib.animation as manimation\n",
    "\n",
    "FFMpegWriter = manimation.writers['ffmpeg']\n",
    "metadata = dict(title='Movie Test', artist='Matplotlib',\n",
    "                comment='Movie support!')\n",
    "writer = FFMpegWriter(fps=15, metadata=metadata)\n",
    "\n",
    "ilen = ds_subset.time.shape[0]\n",
    "ds_subset = ds_all.sel(time=slice(np.datetime64('2000-01-01'),np.datetime64('2018-12-31')),lon=slice(175,228),lat=slice(62,48),depth=15)\n",
    "\n",
    "fig, ax0 = plt.subplots(1,1,figsize=(4,4))\n",
    "im=ax0.pcolormesh(ds_subset.lon,ds_subset.lat,ds_subset.spd[0,:,:],vmin=0,vmax=.3)\n",
    "fig.colorbar(im,ax=ax0)\n",
    "with writer.saving(fig, \"F:/data/NASA_biophysical/movies/writer_test.mp4\", 100):\n",
    "    for i in range(ilen):\n",
    "        fig, ax0 = plt.subplots(1,1,figsize=(4,4))\n",
    "        im=ax0.pcolormesh(ds_subset.lon,ds_subset.lat,ds_subset.spd[i,:,:],vmin=0,vmax=.3)\n",
    "        fig.colorbar(im,ax=ax0)\n",
    "        writer.grab_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pcolor(lons,lats):\n",
    "\n",
    "    class UpdateQuad(object):\n",
    "\n",
    "        def __init__(self,ax, map_object, lons, lats):\n",
    "            self.ax = ax\n",
    "            self.m  = map_object\n",
    "            self.lons = lons\n",
    "            self.lats = lats\n",
    "            vmin = 0\n",
    "            vmax = 1\n",
    "            self.ydim, self.xdim = lons.shape\n",
    "\n",
    "            self.z = np.zeros((self.ydim-1,self.xdim-1))\n",
    "\n",
    "            levels = MaxNLocator(nbins=15).tick_values(vmin,vmax)\n",
    "            cmap = plt.cm.cool\n",
    "            norm = BoundaryNorm(levels, ncolors=cmap.N, clip=True)\n",
    "            x, y = self.m(lons, lats)\n",
    "\n",
    "            self.quad = self.ax.pcolormesh(x, y, self.z, alpha=0.9,\n",
    "                                           norm=norm, cmap=cmap,\n",
    "                                           vmin=vmin, vmax=vmax)\n",
    "        def init(self):\n",
    "            print('update init')\n",
    "            self.quad.set_array(np.asarray([]))\n",
    "            return self.quad\n",
    "\n",
    "        def __call__(self,i):\n",
    "\n",
    "            for i in range(self.ydim-1):\n",
    "                for j in range(self.xdim-1):\n",
    "                    self.z[i,j]=random.random()\n",
    "\n",
    "            self.quad.set_array(self.z.ravel())\n",
    "\n",
    "            return self.quad\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    m = Basemap(width=2000000,height=2000000,\n",
    "                resolution='l', projection='laea',\\\n",
    "                lat_ts=10.,\\\n",
    "                lat_0=64.,lon_0=10., ax=ax)\n",
    "\n",
    "    m.fillcontinents()\n",
    "\n",
    "    ud = UpdateQuad(ax, m, lons, lats)\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, ud, init_func=ud.init,\n",
    "                                   frames=20,  blit=False)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return ud.quad\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.animation as animation\n",
    "    from mpl_toolkits.basemap import Basemap\n",
    "    import numpy as np\n",
    "    import random\n",
    "    from matplotlib.colors import BoundaryNorm\n",
    "    from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "    lons = np.linspace(-5.,25., num = 25)[:50]\n",
    "    lats = np.linspace(56., 71., num = 25)[:50]\n",
    "    lons,lats =  np.meshgrid(lons,lats)\n",
    "\n",
    "    quad = plot_pcolor(lons,lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# Some global variables to define the whole run\n",
    "total_number_of_frames = ds_subset.time.shape[0]\n",
    "\n",
    "def animate(frame):\n",
    "#    \"\"\"\n",
    "#    Animation function. Takes the current frame number (to select the potion of\n",
    "#    data to plot) and a line object to update.\n",
    "#    \"\"\"\n",
    "    # Not strictly neccessary, just so we know we are stealing these from\n",
    "    # the global scope\n",
    "    global ds_subset, image\n",
    "    # We want up-to and _including_ the frame'th element\n",
    "    image.set_array(ds_subset[frame,:,:])\n",
    "    return image\n",
    "\n",
    "# Now we can do the plotting!\n",
    "fig, ax = plt.subplots(1, figsize=(1, 1))\n",
    "# Remove a bunch of stuff to make sure we only 'see' the actual imshow\n",
    "# Stretch to fit the whole plane\n",
    "fig.subplots_adjust(0, 0, 1, 1)\n",
    "# Remove bounding line\n",
    "ax.axis(\"off\")\n",
    "# Initialise our plot. Make sure you set vmin and vmax!\n",
    "image = ax.imshow(ds_subset.spd[0,:,:], vmin=0, vmax=.5)\n",
    "\n",
    "animation = FuncAnimation(\n",
    "    # Your Matplotlib Figure object\n",
    "    fig,\n",
    "    # The function that does the updating of the Figure\n",
    "    animate,\n",
    "    # Frame information (here just frame number)\n",
    "    np.arange(total_number_of_frames),\n",
    "    # Extra arguments to the animate function\n",
    "    fargs=[],\n",
    "    # Frame-time in ms; i.e. for a given frame-rate x, 1000/x\n",
    "    interval=1000 / 25\n",
    ")\n",
    "\n",
    "# Try to set the DPI to the actual number of pixels you're plotting\n",
    "animation.save(\"F:/data/NASA_biophysical/movies/writer_test2.mp4\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to make movie\n",
    "ds_all\n",
    "hv.extension('bokeh')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%output holomap='scrubber'\n",
    "%%opts Image style(cmap='rainbow') plot[colorbar=True]\n",
    "%%opts Image [width=500, height=400]\n",
    "opts = dict(cmap='rainbow', colorbar=True, width=300, height=230, axiswise=True)\n",
    "hv_ds = hv.Dataset(ds_all.spd[1:150,0,:,:])\n",
    "img = hv_ds.to(hv.Image, ['lon', 'lat']).options(**opts)\n",
    "#img.options(colorbar=True, width=300, height=230, axiswise=True)\n",
    "img.redim.range(spd=(0,.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.save(img, 'Spd_half_A.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output holomap='scrubber'\n",
    "%%opts Image style(cmap='viridis') plot[colorbar=True]\n",
    "%%opts Image [width=500, height=400]\n",
    "opts = dict(cmap='rainbow', colorbar=True, width=300, height=230, axiswise=True)\n",
    "hv_ds = hv.Dataset(ds_all.spd[100:300,0,:,:])\n",
    "img = hv_ds.to(hv.Image, ['lon', 'lat']).options(**opts)\n",
    "#img.options(colorbar=True, width=300, height=230, axiswise=True)\n",
    "img.redim.range(spd=(0,.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.save(img, 'Spd_half_B.html', backend='bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('matplotlib')\n",
    "\n",
    "air = xr.tutorial.load_dataset('air_temperature')\n",
    "ds = hv.Dataset(air.isel(time=range(100)))\n",
    "images = ds.to(hv.Image, ['lon', 'lat']).options(fig_inches=(10, 5), colorbar=True, cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y, X = np.meshgrid(ds.latitude, ds.longitude)\n",
    "#ds = ds.sel(longitude=slice(110,250),latitude=slice(65,15))\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as colors\n",
    "for imon in range (5,6): #13):\n",
    "    #ds = ds.sel(lon=slice(110,250),lat=slice(65,15))\n",
    "    X = ds.lon.values\n",
    "    Y = ds.lat.values\n",
    "    U = ds.u[imon,0,:,:]\n",
    "    V = ds.v[imon,0,:,:]\n",
    "    speed = np.sqrt(U*U + V*V)\n",
    "    speed = speed.fillna(0)\n",
    "    lws = 10*speed / speed.max()\n",
    "\n",
    "    fig0, ax0 = plt.subplots()\n",
    "    strm = ax0.streamplot(X,Y, U, V, density=6,color=V.values,linewidth=lws.values, cmap='seismic',norm=colors.Normalize(vmin=-.5,vmax=.5))\n",
    "    fig0.colorbar(strm.lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ds2 = ds.sel(lon=slice(110,179),lat=slice(65,5))\n",
    "    lons1 = ds2.lon.values\n",
    "    lons1[lons1 > 180] = lons1[lons1 > 180] - 360.  #wrap -180-180\n",
    "    lats1 = ds2.lat.values\n",
    "    \n",
    "#    lons0, lats0 = np.meshgrid(lons1,lats1)\n",
    "    X = lons1 \n",
    "    Y = lats1\n",
    "    U = ds2.u[imon,0,:,:]\n",
    "    V = ds2.v[imon,0,:,:]\n",
    "    speed = np.sqrt(U*U + V*V)\n",
    "    speed = speed.fillna(0)\n",
    "    lws = 10*speed / speed.max()\n",
    "    \n",
    "    Xg, Yg = np.meshgrid(X,Y)\n",
    "    input_projection = ccrs.PlateCarree()\n",
    "    #ax = plt.subplot(projection=output_projection)\n",
    "    #ax.streamplot(X, Y, U, V, transform=input_projection)\n",
    "#    ax0 = plt.axes(projection=ccrs.PlateCarree())\n",
    "#    ax0 = fig0.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=180.0))\n",
    "#    ax0.set_extent([-110, 110, 5, 65], crs=ccrs.PlateCarree(central_longitude=180.0))\n",
    "#    ax0.coastlines()\n",
    "\n",
    "#    fig0, ax0 = plt.subplots()\n",
    "\n",
    "    #fig0, ax0 = plt.subplots()\n",
    "    #ax0 = plt.axes(projection=ccrs.PlateCarree())\n",
    "    ax0 = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))\n",
    "    strm = ax0.streamplot(X,Y, U, V, density=6,color=V.values,linewidth=lws.values, cmap='seismic',norm=colors.Normalize(vmin=-.5,vmax=.5), transform = input_projection)\n",
    "    fig0.colorbar(strm.lines)\n",
    "\n",
    "    #fig0, ax0 = plt.figure(figsize=(10, 5))\n",
    "    #strm = ax0.streamplot(X,Y, U, V, density=6,color=V.values,linewidth=lws.values, cmap='seismic',\n",
    "    #                      norm=colors.Normalize(vmin=-.5,vmax=.5)) #, transform=input_projection)\n",
    "#    ax0.coastlines()\n",
    "#    fig0.colorbar(strm.lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Y, X = np.meshgrid(ds.latitude, ds.longitude)\n",
    "#ds = ds.sel(longitude=slice(110,250),latitude=slice(65,15))\n",
    "\n",
    "for imon in range (5,6): #13):\n",
    "    #ds = ds.sel(lon=slice(110,250),lat=slice(65,15))\n",
    "    lons1 = ds.lon.values\n",
    "    lons1[lons1 > 180] = lons1[lons1 > 180] - 360.  #wrap -180-180\n",
    "    lats1 = ds.lat.values\n",
    "    \n",
    "#    lons0, lats0 = np.meshgrid(lons1,lats1)\n",
    "    X = lons1 \n",
    "    Y = lats1\n",
    "    U = ds.u[imon,0,:,:]\n",
    "    V = ds.v[imon,0,:,:]\n",
    "    Vnorm = V/abs(V).max()\n",
    "    speed = np.sqrt(U*U + V*V)\n",
    "    speed = speed.fillna(0)\n",
    "    lws = 10*speed / speed.max()\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "#    map = Basemap(projection='cyl',llcrnrlat=lats1[-1],llcrnrlon=lons1[0],\n",
    "#                  urcrnrlat=lats1[0],urcrnrlon=lons1[-1],resolution='l')\n",
    "\n",
    "    map = Basemap(projection='lcc', llcrnrlon=110, llcrnrlat=5, \n",
    "                  urcrnrlon=-110, urcrnrlat=65,lat_0=5, lon_0=-98.)\n",
    "    map.drawcoastlines(linewidth=0.5)\n",
    "    strm = map.streamplot(X,Y, U, V, latlon=True, density=6,color=V.values,linewidth=lws.values, cmap='seismic',norm=colors.Normalize(vmin=-.5,vmax=.5))\n",
    "    #norm = mpl.colors.Normalize(vmin=-.5,vmax=.5)\n",
    "    #fig0.colorbar(strm.lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# llcrnrlat,llcrnrlon,urcrnrlat,urcrnrlon\n",
    "# are the lat/lon values of the lower left and upper right corners\n",
    "# of the map.\n",
    "# resolution = 'c' means use crude resolution coastlines.\n",
    "m = Basemap(projection='cyl',llcrnrlat=-90,urcrnrlat=90,\\\n",
    "            llcrnrlon=110,urcrnrlon=-110,resolution='c')\n",
    "m.drawcoastlines()\n",
    "m.fillcontinents(color='coral',lake_color='aqua')\n",
    "# draw parallels and meridians.\n",
    "m.drawparallels(np.arange(-90.,91.,30.))\n",
    "m.drawmeridians(np.arange(-180.,181.,60.))\n",
    "m.drawmapboundary(fill_color='aqua')\n",
    "plt.title(\"Equidistant Cylindrical Projection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xg.shape,xx.shape,yy.shape,U.shape,V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = ds.lon.values\n",
    "lons[lons > 180] = lons[lons > 180] - 360.\n",
    "lons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape,Y.shape,U.shape,V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "X = ds.lon.values\n",
    "Y = ds.lat.values\n",
    "U = ds.u[:,0,:,:]\n",
    "V = ds.v[:,0,:,:]\n",
    "Vnorm = V/abs(V).max()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#data = np.random.rand(2, 25)\n",
    "l, = ax0.streamplot(X,Y, U, V, density=6,color=Vnorm.values, linewidth=lws.values, cmap='seismic')\n",
    "line_ani = animation.FuncAnimation(fig, update_line, 25, fargs=(data, l),\n",
    "                                   interval=50, blit=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(V.min(),V.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cmap = colorbrewer.get_map('Spectral', 'diverging', 11, reverse=True).mpl_colormap\n",
    "fig = plt.figure(figsize=(11.7,8.3))\n",
    "m = Basemap(projection='merc', lat_0 = 40, lon_0 = -179, resolution = 'l', area_thresh = 0.1,\n",
    "            llcrnrlon=-110.0, llcrnrlat=25.0,urcrnrlon=-114.0, urcrnrlat=38.)\n",
    "m.bluemarble()\n",
    "lat_grid, lon_grid = np.meshgrid(ds.lat.values, ds.lon.values)\n",
    "x,y = m(lon_grid,lat_grid)\n",
    "cs = m.pcolormesh(x,y, speed.transpose(), cmap=cmap, vmin = 0, vmax = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# setup Lambert Conformal basemap.\n",
    "# set resolution=None to skip processing of boundary datasets.\n",
    "m = Basemap(width=12000000,height=9000000,projection='lcc',\n",
    "            resolution=None,lat_1=2.,lat_2=65,lat_0=50,lon_0=-110.)\n",
    "m.bluemarble(ax=None, scale=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "lats1=[-25, 66]\n",
    "lons1=[60, 179.95]\n",
    "fig=plt.figure()\n",
    "fig.set_size_inches((10, 9))\n",
    "\n",
    "ax1=fig.add_subplot(121)\n",
    "ax2=fig.add_subplot(122)\n",
    "\n",
    "bmap=Basemap(projection='merc',\\\n",
    "        llcrnrlat=lats1[0], llcrnrlon=lons1[0],\\\n",
    "        urcrnrlat=lats1[1], urcrnrlon=lons1[1],\\\n",
    "        lon_0=(lons1[0]+lons1[1])/2.,\\\n",
    "        ax=ax1)\n",
    "\n",
    "bmap.bluemarble(ax = ax1)\n",
    "\n",
    "ax1.set_position([0, 0, 0.8, 1])\n",
    "\n",
    "lats2=[-25,66]\n",
    "lons2=[-179.95, -150]\n",
    "bmap=Basemap(projection='merc',\\\n",
    "        llcrnrlat=lats2[0], llcrnrlon=lons2[0],\\\n",
    "        urcrnrlat=lats2[1], urcrnrlon=lons2[1],\\\n",
    "        lon_0=(lons2[0]+lons2[1])/2.,\\\n",
    "        ax=ax2)\n",
    "\n",
    "bmap.bluemarble(ax = ax2)\n",
    "ax2.set_position([0.8, 0, 0.2, 1])\n",
    "\n",
    "ax1.set_aspect('auto')\n",
    "ax2.set_aspect('auto')\n",
    "\n",
    "ax1.set_adjustable('datalim')\n",
    "ax2.set_adjustable('datalim')\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.u[0,0,:,:].plot()\n",
    "ds.u[0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make monthly climatology, need to drop 'year' coordinate value for mean to work right\n",
    "for lyr in range(1993,2019):\n",
    "    filename = dir_data + str(lyr) + 'monthly_data_oscar.nc'\n",
    "    ds=xr.open_dataset(filename)\n",
    "    ds2 = ds.drop('year')\n",
    "    if lyr==1993:\n",
    "        ds_clim = ds2\n",
    "    else:\n",
    "        ds_clim = xr.concat([ds_clim,ds2],dim = 'time')\n",
    "    ds.close()\n",
    "ds_clim2 = ds_clim.groupby('time.month').mean('time')\n",
    "ds_clim2.to_netcdf(dir_data + 'climatology_1993_2018_monthly_data_oscar.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make monthly climatology, need to drop 'year' coordinate value for mean to work right\n",
    "for lyr in range(2000,2019):\n",
    "    filename = dir_data + str(lyr) + 'monthly_data_oscar.nc'\n",
    "    ds=xr.open_dataset(filename)\n",
    "    ds2 = ds.drop('year')\n",
    "    if lyr==2000:\n",
    "        ds_clim = ds2\n",
    "    else:\n",
    "        ds_clim = xr.concat([ds_clim,ds2],dim = 'time')\n",
    "    ds.close()\n",
    "ds_clim2 = ds_clim.groupby('time.month').mean('time')\n",
    "ds_clim2.to_netcdf(dir_data + 'climatology_2000_2018_monthly_data_oscar.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD OLD OLD OLD OLD OLD CODE\n",
    "#make oscar climatology, OLD version of code\n",
    "#dir_data='F:/data/sat_data/oscar/L4/oscar_third_deg/'\n",
    "dir_clim='F:/data/sat_data/oscar/L4/oscar_third_deg/climatology/'\n",
    "dir_data = 'https://podaac-opendap.jpl.nasa.gov/opendap/allData/oscar/preview/L4/oscar_third_deg/'\n",
    "for lyr in range(1993,2018):\n",
    "    filename = dir_data + 'oscar_vel' + str(lyr).zfill(4) + '.nc.gz'\n",
    "    ds=xr.open_dataset(filename,drop_variables=['um','vm'])\n",
    "    ds_count=data_ones(ds)\n",
    "    #in order to add up the data the time arrays have to be aligned otherwise xarray doesn't know what to do with it\n",
    "    ds['time'] = ds['time'] - np.datetime64(lyr,'Y')\n",
    "    ds_count['time'] = ds_count['time'] - np.datetime64(lyr,'Y')\n",
    "    if lyr==1993:\n",
    "        ds2=ds.fillna(0)\n",
    "        ds_count2=ds_count.fillna(0)\n",
    "        ds_summer=ds2\n",
    "        ds_counter = ds_count2\n",
    "    else:\n",
    "        ds2 = ds.interp_like(ds_summer.time)\n",
    "        ds_count2 = ds_count.interp_like(ds_summer.time)\n",
    "        ds2=ds2.fillna(0)\n",
    "        ds_count2=ds_count2.fillna(0)\n",
    "        ds_summer=ds_summer + ds2\n",
    "        ds_counter = ds_counter + ds_count2\n",
    "    print(lyr)\n",
    "    print(ds.u.shape)\n",
    "    print(ds_summer.u.shape)\n",
    "   # print(ds_counter.u.shape)\n",
    "   # print(ds.u.shape)\n",
    "   # print(ds.time.data[0:20])\n",
    "ds_ave = ds_summer / ds_counter\n",
    "ds_ave.to_netcdf(dir_clim + 'oscar_v2009_1993_2016_climatology_12202118.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "tem_date=dt.datetime(2016,1,15)\n",
    "print(tem_date)\n",
    "filename = 'https://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/godas/dbss_obml.2016.nc'\n",
    "#filename = 'F:/data/model_data/godas/dbss_obml.2017.nc'\n",
    "ds = xr.open_dataset(filename)\n",
    "ds_storm = ds.interp(time = tem_date)\n",
    "ds_storm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            dir_ccmp='F:/data/sat_data/ccmp/v02.0/Y'\n",
    "            storm_date = dt.datetime(2015,1,1)\n",
    "            syr, smon, sdym, sjdy=str(storm_date.year),str(storm_date.month),str(storm_date.day),str(storm_date.timetuple().tm_yday)\n",
    "            fname_tem='/CCMP_Wind_Analysis_' + syr + smon.zfill(2) + sdym.zfill(2) + '_V02.0_L3.0_RSS.nc'\n",
    "            ccmp_filename = dir_ccmp + syr + '/M' + smon.zfill(2) + fname_tem      \n",
    "            ds=xr.open_dataset(ccmp_filename,drop_variables=['nobs'])\n",
    "            ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_storm.dbss_obml.plot(vmin=0,vmax=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_storm.dbss_obml[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plat around with lon mask for part of region along calif coast\n",
    "ds_subset = ds_all.sel(lon=slice(165,228),lat=slice(61,48))\n",
    "curr_mean = ds_subset.spd.mean('time')\n",
    "curr_mean2=curr_mean.where((curr_mean.lon<180) & (curr_mean.lat<53) | (curr_mean.lon>180) & (curr_mean.lat<62))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i don't understand why but the where above which is just to mask out the arctic ocean area for some\n",
    "#reason sets the 180 longitude to zero so I reset it to the values manually\n",
    "curr_mean2[:,45]=curr_mean[:,45]\n",
    "curr_max = curr_mean2.max('lat')\n",
    "curr_max_location = np.argmax(curr_mean2,0)\n",
    "curr_std = ds_subset.spd.std('time')\n",
    "cmask = curr_std.where(curr_std>=0.048)\n",
    "[lon2d,lat2d]=np.meshgrid(cmask.lon,cmask.lat)\n",
    "lat2dm = np.where(np.isnan(cmask), lat2d*np.nan,lat2d)\n",
    "lower_boundary = np.nanmin(lat2dm,0)\n",
    "lower_boundary_index = np.nanargmin(lat2dm,0)\n",
    "plt.subplots(1,1,figsize=(13,6.2))\n",
    "#fig, axarr = plt.subplots(1,1,figsize=(12,3.5))\n",
    "gs1 = gridspec.GridSpec(1, 2)\n",
    "ax = plt.subplot(gs1[0],projection=ccrs.Mercator(central_longitude=180,min_latitude=48, max_latitude=62))\n",
    "ax.background_img(name='ne_shaded', resolution='low')\n",
    "#ax.background_img(name='BM', resolution='high')\n",
    "ax.set_extent([165,-122,48,62])\n",
    "mm = ax.pcolormesh(ds_subset.lon,ds_subset.lat,ds_subset.spd.mean('time'),vmin=0, vmax=.2, transform=ccrs.PlateCarree(),cmap='viridis' )\n",
    "ax.plot(ds_subset.lon,ds_subset.lat[curr_max_location],'r',markersize=2,linewidth=2, transform=ccrs.PlateCarree())\n",
    "ax.coastlines(resolution='10m');\n",
    "#plt.title(str(ds_subset.time[120].data))\n",
    "plt.colorbar(mm,ax=ax,shrink=.3,pad=.01,label='Current Velocity Mean(ms$^{-1}$)')\n",
    "\n",
    "ax = plt.subplot(gs1[1],projection=ccrs.Mercator(central_longitude=180,min_latitude=48, max_latitude=62))\n",
    "ax.background_img(name='ne_shaded', resolution='low')\n",
    "#ax.background_img(name='BM', resolution='high')\n",
    "ax.set_extent([165,-122,48,62])\n",
    "mm = ax.pcolormesh(ds_subset.lon,ds_subset.lat,ds_subset.spd.std('time'),vmin=0, vmax=.05, transform=ccrs.PlateCarree(),cmap='viridis' )\n",
    "ax.plot(ds_subset.lon,ds_subset.lat[curr_max_location],'r',markersize=2,linewidth=2, transform=ccrs.PlateCarree())\n",
    "ax.plot(ds_subset.lon,ds_subset.lat[curr_max_location-2],'k',markersize=2,linewidth=2, transform=ccrs.PlateCarree())\n",
    "ax.plot(ds_subset.lon,ds_subset.lat[lower_boundary_index],'k',markersize=2,linewidth=2, transform=ccrs.PlateCarree())\n",
    "ax.coastlines(resolution='10m');\n",
    "#plt.title(str(ds_subset.time[120].data))\n",
    "plt.colorbar(mm,ax=ax,shrink=.3,pad=.01,label='Current Velocity STD (ms$^{-1}$)')\n",
    "plt.savefig('F:/data/NASA_biophysical/telecon_figs/mean_std_current_speed_mask.png', dpi=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
